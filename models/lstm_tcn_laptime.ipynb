{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM/TCN lap-time model\n",
        "A lightweight sequence model using the same features as `xgboost_laptime.ipynb` with an overtaking-aware simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2abf07d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, random, math\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\n",
        "    \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ")\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2c6435de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 198,633 rows from fastf1_lap_dataset2.csv\n",
            "                      session_key  year  circuit_id\n",
            "0  2018_abu_dhabi_grand_prix_race  2018  yas_marina\n",
            "4  2018_abu_dhabi_grand_prix_race  2018  yas_marina\n",
            "5  2018_abu_dhabi_grand_prix_race  2018  yas_marina\n",
            "6  2018_abu_dhabi_grand_prix_race  2018  yas_marina\n",
            "7  2018_abu_dhabi_grand_prix_race  2018  yas_marina\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset_path = Path(\"fastf1_lap_dataset2.csv\")\n",
        "if not dataset_path.exists():\n",
        "    dataset_path = Path(\"fastf1_lap_dataset.csv\")\n",
        "\n",
        "max_rows = None  # set an int to subsample for faster experiments\n",
        "df = pd.read_csv(dataset_path, nrows=max_rows)\n",
        "print(f\"Loaded {len(df):,} rows from {dataset_path}\")\n",
        "\n",
        "df = df[df[\"lap_time_s\"].notna()].copy()\n",
        "df = df[df[\"lap_time_s\"] > 0].copy()\n",
        "print(df[[\"session_key\", \"year\", \"circuit_id\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "91cbe7b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared modeling frame: 194,736 rows, 197 sessions, 43 drivers.\n"
          ]
        }
      ],
      "source": [
        "# Feature engineering (mirror xgboost_laptime)\n",
        "race_df = df[(~df[\"safety_car_this_lap\"]) & (~df[\"virtual_sc_this_lap\"]) & df[\"lap_time_s\"].notna()].copy()\n",
        "circuit_baseline = (\n",
        "    race_df.groupby(\"circuit_id\")[\"lap_time_s\"].median().reset_index().rename(columns={\"lap_time_s\": \"circuit_median_lap\"})\n",
        ")\n",
        "df = df.merge(circuit_baseline, on=\"circuit_id\", how=\"left\")\n",
        "df[\"lap_delta_s\"] = df[\"lap_time_s\"] - df[\"circuit_median_lap\"]\n",
        "\n",
        "# Driver skill metric per session, then averaged\n",
        "session_col = \"session_key\"\n",
        "clean = race_df.copy()\n",
        "session_stats = (\n",
        "    clean.groupby(session_col)[\"lap_time_s\"].agg(session_median_lap=\"median\", session_std_lap=\"std\").reset_index()\n",
        ")\n",
        "clean = clean.merge(session_stats, on=session_col, how=\"left\")\n",
        "clean[\"session_std_lap\"] = clean[\"session_std_lap\"].replace(0, np.nan)\n",
        "clean[\"session_perf_z\"] = -(clean[\"lap_time_s\"] - clean[\"session_median_lap\"]) / clean[\"session_std_lap\"]\n",
        "clean[\"session_perf_z\"] = clean[\"session_perf_z\"].fillna(0.0)\n",
        "\n",
        "driver_session_skill = clean.groupby([\"driver_id\", session_col])[\"session_perf_z\"].mean().reset_index()\n",
        "driver_skill_raw = driver_session_skill.groupby(\"driver_id\")[\"session_perf_z\"].mean()\n",
        "driver_skill = (driver_skill_raw - driver_skill_raw.mean()) / driver_skill_raw.std()\n",
        "\n",
        "df = df.merge(driver_skill.rename(\"driver_skill\"), on=\"driver_id\", how=\"left\")\n",
        "df[\"driver_skill\"] = df[\"driver_skill\"].fillna(0.0)\n",
        "\n",
        "df[\"race_progress\"] = df[\"lap_number\"] / df[\"total_race_laps\"].replace(0, np.nan).fillna(1.0)\n",
        "df[\"laps_remaining\"] = df[\"total_race_laps\"] - df[\"lap_number\"]\n",
        "\n",
        "df[\"gap_to_ahead_s\"] = df.groupby([\"session_key\", \"driver_id\"])[\"gap_to_ahead_s\"].ffill().bfill().fillna(0.0)\n",
        "df[\"laps_on_current_tyre\"] = df[\"laps_on_current_tyre\"].fillna(0).astype(int)\n",
        "df[\"rainfall\"] = df[\"rainfall\"].astype(float).fillna(0.0)\n",
        "df[\"safety_car_this_lap\"] = df[\"safety_car_this_lap\"].astype(float)\n",
        "\n",
        "feature_cols = [\n",
        "    \"laps_on_current_tyre\",\n",
        "    \"safety_car_this_lap\",\n",
        "    \"race_progress\",\n",
        "    \"rainfall\",\n",
        "    \"current_position\",\n",
        "    \"gap_to_ahead_s\",\n",
        "    \"year\",\n",
        "    \"driver_skill\",\n",
        "]\n",
        "target_col = \"lap_delta_s\"\n",
        "\n",
        "df_model = df[\n",
        "    feature_cols\n",
        "    + [\"tyre_compound\", \"circuit_id\", \"driver_id\", \"session_key\", \"lap_number\", \"lap_delta_s\", \"total_race_laps\"]\n",
        "].copy()\n",
        "df_model[\"tyre_compound\"] = df_model[\"tyre_compound\"].fillna(\"UNKNOWN\")\n",
        "\n",
        "circuit_median_map = circuit_baseline.set_index(\"circuit_id\")[\"circuit_median_lap\"].to_dict()\n",
        "driver_skill_map = driver_skill.to_dict()\n",
        "\n",
        "print(\n",
        "    f\"Prepared modeling frame: {len(df_model):,} rows, {df_model['session_key'].nunique()} sessions, \"\n",
        "    f\"{df_model['driver_id'].nunique()} drivers.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "aa3dcdea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train sessions: 157, Val sessions: 40\n",
            "Vocab sizes -> drivers 43, circuits 35, compounds 9\n"
          ]
        }
      ],
      "source": [
        "# Split sessions and build scalers/vocabs\n",
        "seq_len = 12\n",
        "batch_size = 64\n",
        "num_epochs = 6\n",
        "max_train_sessions = 300  # keep small for quick runs; set None for all\n",
        "max_val_sessions = 80\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "session_keys = df_model[\"session_key\"].unique()\n",
        "rng.shuffle(session_keys)\n",
        "\n",
        "split_idx = int(0.8 * len(session_keys))\n",
        "train_sessions = list(session_keys[:split_idx])\n",
        "val_sessions = list(session_keys[split_idx:])\n",
        "\n",
        "if max_train_sessions:\n",
        "    train_sessions = train_sessions[:max_train_sessions]\n",
        "if max_val_sessions:\n",
        "    val_sessions = val_sessions[:max_val_sessions]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_model[df_model[\"session_key\"].isin(train_sessions)][feature_cols])\n",
        "\n",
        "compounds = sorted(df_model[\"tyre_compound\"].unique().tolist())\n",
        "drivers = sorted(df_model[\"driver_id\"].unique().tolist())\n",
        "circuits = sorted(df_model[\"circuit_id\"].unique().tolist())\n",
        "compound2idx = {c: i for i, c in enumerate(compounds)}\n",
        "driver2idx = {d: i for i, d in enumerate(drivers)}\n",
        "circuit2idx = {c: i for i, c in enumerate(circuits)}\n",
        "\n",
        "print(f\"Train sessions: {len(train_sessions)}, Val sessions: {len(val_sessions)}\")\n",
        "print(f\"Vocab sizes -> drivers {len(drivers)}, circuits {len(circuits)}, compounds {len(compounds)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f500182c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(117063, 32608)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataset and dataloaders\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, df_slice, sessions, seq_len):\n",
        "        self.samples = []\n",
        "        df_slice = df_slice[df_slice[\"session_key\"].isin(sessions)].copy()\n",
        "        grouped = df_slice.groupby([\"session_key\", \"driver_id\"])\n",
        "        for (sess, drv), g in grouped:\n",
        "            g = g.sort_values(\"lap_number\")\n",
        "            if len(g) <= seq_len:\n",
        "                continue\n",
        "            num = scaler.transform(g[feature_cols])\n",
        "            tyre = g[\"tyre_compound\"].map(compound2idx).fillna(0).astype(int).to_numpy()\n",
        "            lap_delta = g[\"lap_delta_s\"].to_numpy()\n",
        "            circ_idx = circuit2idx.get(g[\"circuit_id\"].iloc[0], 0)\n",
        "            drv_idx = driver2idx.get(drv, 0)\n",
        "            for i in range(seq_len, len(g)):\n",
        "                self.samples.append(\n",
        "                    (\n",
        "                        num[i - seq_len : i].astype(np.float32),\n",
        "                        tyre[i - seq_len : i].astype(np.int64),\n",
        "                        drv_idx,\n",
        "                        circ_idx,\n",
        "                        float(lap_delta[i]),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    nums, tyres, drivers_idx, circuits_idx, targets = zip(*batch)\n",
        "    num_t = torch.tensor(np.stack(nums), dtype=torch.float32)\n",
        "    tyre_t = torch.tensor(np.stack(tyres), dtype=torch.long)\n",
        "    drv_t = torch.tensor(drivers_idx, dtype=torch.long)\n",
        "    circ_t = torch.tensor(circuits_idx, dtype=torch.long)\n",
        "    tgt_t = torch.tensor(targets, dtype=torch.float32)\n",
        "    return num_t, tyre_t, drv_t, circ_t, tgt_t\n",
        "\n",
        "\n",
        "train_ds = SequenceDataset(df_model, train_sessions, seq_len)\n",
        "val_ds = SequenceDataset(df_model, val_sessions, seq_len)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_batch)\n",
        "\n",
        "len(train_ds), len(val_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "90efc376",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LapSequenceModel(\n",
              "  (tyre_emb): Embedding(9, 32)\n",
              "  (driver_emb): Embedding(43, 32)\n",
              "  (circuit_emb): Embedding(35, 32)\n",
              "  (input_proj): Linear(in_features=104, out_features=1280, bias=True)\n",
              "  (tcn1): TCNBlock(\n",
              "    (conv1): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=(2,))\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (act): ReLU()\n",
              "  )\n",
              "  (tcn2): TCNBlock(\n",
              "    (conv1): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (act): ReLU()\n",
              "  )\n",
              "  (lstm): LSTM(1280, 1280, batch_first=True)\n",
              "  (head): Sequential(\n",
              "    (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "    (2): Linear(in_features=1280, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model definition: small TCN block feeding an LSTM\n",
        "class TCNBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, dilation=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.conv2 = nn.Conv1d(channels, channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.act(self.conv1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.act(self.conv2(x))\n",
        "        x = self.dropout(x)\n",
        "        trim = x.size(-1) - residual.size(-1)\n",
        "        if trim > 0:\n",
        "            x = x[..., :-trim]\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class LapSequenceModel(nn.Module):\n",
        "    def __init__(self, num_numeric, tyre_vocab, driver_vocab, circuit_vocab, emb_dim=16, tcn_channels=64, lstm_hidden=64, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.tyre_emb = nn.Embedding(tyre_vocab, emb_dim)\n",
        "        self.driver_emb = nn.Embedding(driver_vocab, emb_dim)\n",
        "        self.circuit_emb = nn.Embedding(circuit_vocab, emb_dim)\n",
        "\n",
        "        input_dim = num_numeric + emb_dim * 3\n",
        "        self.input_proj = nn.Linear(input_dim, tcn_channels)\n",
        "        self.tcn1 = TCNBlock(tcn_channels, kernel_size=3, dilation=1, dropout=dropout)\n",
        "        self.tcn2 = TCNBlock(tcn_channels, kernel_size=3, dilation=2, dropout=dropout)\n",
        "        self.lstm = nn.LSTM(tcn_channels, lstm_hidden, num_layers=1, batch_first=True)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(lstm_hidden),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(lstm_hidden, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, num_feats, tyre_idx, driver_idx, circuit_idx):\n",
        "        tyre_e = self.tyre_emb(tyre_idx)\n",
        "        drv_e = self.driver_emb(driver_idx).unsqueeze(1).expand(-1, num_feats.size(1), -1)\n",
        "        circ_e = self.circuit_emb(circuit_idx).unsqueeze(1).expand(-1, num_feats.size(1), -1)\n",
        "\n",
        "        x = torch.cat([num_feats, tyre_e, drv_e, circ_e], dim=-1)\n",
        "        x = self.input_proj(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.tcn1(x)\n",
        "        x = self.tcn2(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last = lstm_out[:, -1, :]\n",
        "        return self.head(last).squeeze(-1)\n",
        "\n",
        "\n",
        "model = LapSequenceModel(\n",
        "    num_numeric=len(feature_cols),\n",
        "    tyre_vocab=len(compounds),\n",
        "    driver_vocab=len(drivers),\n",
        "    circuit_vocab=len(circuits),\n",
        "    emb_dim=32,\n",
        "    tcn_channels=1280,\n",
        "    lstm_hidden=1280,\n",
        "    dropout=0.2,\n",
        ").to(DEVICE)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fa5b9435",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss=92.3381 val_loss=56.5279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train_loss=92.4715 val_loss=53.2441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train_loss=91.5723 val_loss=55.4026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                         \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mmax\u001b[39m(count, \u001b[32m1\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     train_loss = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     val_loss = run_epoch(val_loader, train=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(loader, train)\u001b[39m\n\u001b[32m     22\u001b[39m             torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     23\u001b[39m             optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * \u001b[38;5;28mlen\u001b[39m(tgt_t)\n\u001b[32m     25\u001b[39m     count += \u001b[38;5;28mlen\u001b[39m(tgt_t)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mmax\u001b[39m(count, \u001b[32m1\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def run_epoch(loader, train: bool):\n",
        "    model.train(train)\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "    for num_t, tyre_t, drv_t, circ_t, tgt_t in tqdm(loader, desc=\"train\" if train else \"val\", leave=False):\n",
        "        num_t = num_t.to(DEVICE)\n",
        "        tyre_t = tyre_t.to(DEVICE)\n",
        "        drv_t = drv_t.to(DEVICE)\n",
        "        circ_t = circ_t.to(DEVICE)\n",
        "        tgt_t = tgt_t.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            pred = model(num_t, tyre_t, drv_t, circ_t)\n",
        "            loss = criterion(pred, tgt_t)\n",
        "            if train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "        total_loss += loss.item() * len(tgt_t)\n",
        "        count += len(tgt_t)\n",
        "    return total_loss / max(count, 1)\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = run_epoch(train_loader, train=True)\n",
        "    val_loss = run_epoch(val_loader, train=False)\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7321ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE: 24.5039, RMSE: 4.9501\n",
            "Val   MSE: 46.0531, RMSE: 6.7862\n"
          ]
        }
      ],
      "source": [
        "# Validation metrics\n",
        "import math\n",
        "\n",
        "def eval_metrics(loader):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for num_t, tyre_t, drv_t, circ_t, tgt_t in loader:\n",
        "            num_t = num_t.to(DEVICE)\n",
        "            tyre_t = tyre_t.to(DEVICE)\n",
        "            drv_t = drv_t.to(DEVICE)\n",
        "            circ_t = circ_t.to(DEVICE)\n",
        "            tgt_t = tgt_t.to(DEVICE)\n",
        "            pred = model(num_t, tyre_t, drv_t, circ_t)\n",
        "            diff = pred - tgt_t\n",
        "            total += (diff ** 2).sum().item()\n",
        "            count += tgt_t.numel()\n",
        "    mse = total / max(count, 1)\n",
        "    rmse = math.sqrt(mse)\n",
        "    return mse, rmse\n",
        "\n",
        "train_mse, train_rmse = eval_metrics(train_loader)\n",
        "val_mse, val_rmse = eval_metrics(val_loader)\n",
        "print(f\"Train MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}\")\n",
        "print(f\"Val   MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "331d744a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overtakes</th>\n",
              "      <th>opportunities</th>\n",
              "      <th>raw_rate</th>\n",
              "      <th>overtake_rate</th>\n",
              "      <th>overtake_ease</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>circuit_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>austin</th>\n",
              "      <td>1039</td>\n",
              "      <td>1467</td>\n",
              "      <td>0.708248</td>\n",
              "      <td>0.692439</td>\n",
              "      <td>0.854548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baku</th>\n",
              "      <td>781</td>\n",
              "      <td>1336</td>\n",
              "      <td>0.584581</td>\n",
              "      <td>0.583526</td>\n",
              "      <td>0.543322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>barcelona</th>\n",
              "      <td>1271</td>\n",
              "      <td>1575</td>\n",
              "      <td>0.806984</td>\n",
              "      <td>0.781012</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>budapest</th>\n",
              "      <td>1066</td>\n",
              "      <td>1737</td>\n",
              "      <td>0.613702</td>\n",
              "      <td>0.609859</td>\n",
              "      <td>0.618569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hockenheim</th>\n",
              "      <td>364</td>\n",
              "      <td>434</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.755987</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            overtakes  opportunities  raw_rate  overtake_rate  overtake_ease\n",
              "circuit_id                                                                  \n",
              "austin           1039           1467  0.708248       0.692439       0.854548\n",
              "baku              781           1336  0.584581       0.583526       0.543322\n",
              "barcelona        1271           1575  0.806984       0.781012       0.950000\n",
              "budapest         1066           1737  0.613702       0.609859       0.618569\n",
              "hockenheim        364            434  0.838710       0.755987       0.950000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inference helpers and overtaking model\n",
        "def format_seconds(x: float) -> str:\n",
        "    minutes = int(x // 60)\n",
        "    seconds = x % 60\n",
        "    return f\"{minutes}:{seconds:05.2f}\"\n",
        "\n",
        "\n",
        "def predict_delta_from_history(model, hist_num, hist_tyre, driver_idx, circuit_idx):\n",
        "    model.eval()\n",
        "    num_t = torch.tensor(hist_num, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
        "    tyre_t = torch.tensor(hist_tyre, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
        "    drv_t = torch.tensor([driver_idx], dtype=torch.long, device=DEVICE)\n",
        "    circ_t = torch.tensor([circuit_idx], dtype=torch.long, device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        pred = model(num_t, tyre_t, drv_t, circ_t)\n",
        "    return float(pred.cpu().item())\n",
        "\n",
        "\n",
        "def build_circuit_overtake_model(df, gap_threshold=1.0, min_opps_prior=200):\n",
        "    tmp = df.copy()\n",
        "    tmp = tmp.sort_values([\"session_key\", \"lap_number\", \"current_position\"])\n",
        "\n",
        "    grp = tmp.groupby([\"session_key\", \"driver_id\"])\n",
        "    tmp[\"prev_position\"] = grp[\"current_position\"].shift(1)\n",
        "    tmp[\"prev_gap_to_ahead_s\"] = grp[\"gap_to_ahead_s\"].shift(1)\n",
        "\n",
        "    valid = tmp[\"prev_position\"].notna()\n",
        "    tmp_valid = tmp[valid].copy()\n",
        "    tmp_valid[\"positions_gained\"] = (\n",
        "        tmp_valid[\"prev_position\"] - tmp_valid[\"current_position\"]\n",
        "    ).clip(lower=0)\n",
        "    tmp_valid[\"overtake_event\"] = (tmp_valid[\"positions_gained\"] > 0).astype(int)\n",
        "\n",
        "    overtakes_by_circuit = tmp_valid.groupby(\"circuit_id\")[\"overtake_event\"].sum()\n",
        "    opp_mask = (\n",
        "        (tmp_valid[\"prev_position\"] > 1)\n",
        "        & (tmp_valid[\"prev_gap_to_ahead_s\"].notna())\n",
        "        & (tmp_valid[\"prev_gap_to_ahead_s\"] <= gap_threshold)\n",
        "    )\n",
        "    opportunities_by_circuit = tmp_valid[opp_mask].groupby(\"circuit_id\")[\"driver_id\"].count()\n",
        "\n",
        "    stats = pd.concat([overtakes_by_circuit, opportunities_by_circuit], axis=1).fillna(0.0)\n",
        "    stats.columns = [\"overtakes\", \"opportunities\"]\n",
        "    stats[\"raw_rate\"] = np.where(\n",
        "        stats[\"opportunities\"] > 0,\n",
        "        stats[\"overtakes\"] / stats[\"opportunities\"],\n",
        "        0.0,\n",
        "    )\n",
        "\n",
        "    global_rate = stats[\"raw_rate\"].replace(0.0, np.nan).mean()\n",
        "    if np.isnan(global_rate):\n",
        "        global_rate = 0.05\n",
        "    prior_w = float(min_opps_prior)\n",
        "    stats[\"overtake_rate\"] = (\n",
        "        stats[\"raw_rate\"] * stats[\"opportunities\"] + global_rate * prior_w\n",
        "    ) / (stats[\"opportunities\"] + prior_w)\n",
        "\n",
        "    q_low = stats[\"overtake_rate\"].quantile(0.1)\n",
        "    q_high = stats[\"overtake_rate\"].quantile(0.9)\n",
        "    if q_high <= q_low:\n",
        "        stats[\"overtake_ease\"] = 0.5\n",
        "    else:\n",
        "        norm = (stats[\"overtake_rate\"] - q_low) / (q_high - q_low)\n",
        "        stats[\"overtake_ease\"] = norm.clip(0.05, 0.95)\n",
        "\n",
        "    circuit_overtake_ease = stats[\"overtake_ease\"].to_dict()\n",
        "    return stats, circuit_overtake_ease\n",
        "\n",
        "\n",
        "def overtake_success_probability(attacker_state, defender_state, circuit_id, circuit_overtake_ease, gap_start):\n",
        "    ease = float(circuit_overtake_ease.get(circuit_id, 0.3))\n",
        "    skill_att = float(driver_skill_map.get(attacker_state[\"driver_id\"], 0.0))\n",
        "    skill_def = float(driver_skill_map.get(defender_state[\"driver_id\"], 0.0))\n",
        "    skill_diff = skill_att - skill_def\n",
        "    tyre_adv_laps = defender_state[\"laps_on_current_tyre\"] - attacker_state[\"laps_on_current_tyre\"]\n",
        "    skill_term = 0.15 * np.tanh(skill_diff / 0.5)\n",
        "    tyre_term = 0.10 * np.tanh(tyre_adv_laps / 10.0)\n",
        "    gap_term = -0.15 * np.tanh(max(gap_start, 0.0) / 0.7)\n",
        "    p = 0.2 + 0.6 * ease + skill_term + tyre_term + gap_term\n",
        "    return float(np.clip(p, 0.01, 0.95))\n",
        "\n",
        "\n",
        "def apply_overtakes_for_lap(\n",
        "    circuit_id,\n",
        "    drivers_by_pos,\n",
        "    lap_times,\n",
        "    pred_deltas,\n",
        "    base_lap,\n",
        "    circuit_overtake_ease,\n",
        "    close_gap_threshold=1.0,\n",
        "    fail_gap=0.3,\n",
        "):\n",
        "    lap_times = np.asarray(lap_times, dtype=float).copy()\n",
        "    pred_deltas = np.asarray(pred_deltas, dtype=float).copy()\n",
        "    n = len(drivers_by_pos)\n",
        "    overtake_attempts = np.zeros(n, dtype=bool)\n",
        "    for idx in range(1, n):\n",
        "        follower = drivers_by_pos[idx]\n",
        "        leader = drivers_by_pos[idx - 1]\n",
        "        gap_start = float(follower[\"gap_to_ahead\"])\n",
        "        leader_time = lap_times[idx - 1]\n",
        "        follower_time = lap_times[idx]\n",
        "        gap_end_raw = gap_start + (follower_time - leader_time)\n",
        "        going_to_pass_raw = gap_end_raw < 0.0\n",
        "        close_enough = gap_start <= close_gap_threshold\n",
        "        if not going_to_pass_raw and not close_enough:\n",
        "            continue\n",
        "        overtake_attempts[idx] = True\n",
        "        margin = max(0.0, -gap_end_raw)\n",
        "        base_p = 0.10 + 0.40 * min(margin / 0.5, 1.0)\n",
        "        p_success = base_p * float(circuit_overtake_ease.get(circuit_id, 1.0))\n",
        "        p_success = max(0.0, min(0.95, p_success))\n",
        "        r = np.random.rand()\n",
        "        success = (r < p_success) and going_to_pass_raw\n",
        "        if success:\n",
        "            continue\n",
        "        desired_follower_time = leader_time + fail_gap - gap_start\n",
        "        if desired_follower_time > follower_time:\n",
        "            lap_times[idx] = desired_follower_time\n",
        "    pred_deltas = lap_times - float(base_lap)\n",
        "    return lap_times, pred_deltas, overtake_attempts\n",
        "\n",
        "\n",
        "overtake_stats, circuit_overtake_ease = build_circuit_overtake_model(df)\n",
        "overtake_stats.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f8dfaf70",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Race simulation using the LSTM/TCN model\n",
        "def build_feature_vector(state, lap, total_laps, safety_car_laps, rain_laps):\n",
        "    row = {\n",
        "        \"laps_on_current_tyre\": state[\"laps_on_current_tyre\"] + 1,\n",
        "        \"safety_car_this_lap\": 1.0 if lap in safety_car_laps else 0.0,\n",
        "        \"race_progress\": lap / total_laps,\n",
        "        \"rainfall\": 1.0 if lap in rain_laps else 0.0,\n",
        "        \"current_position\": state[\"position\"],\n",
        "        \"gap_to_ahead_s\": state.get(\"gap_to_ahead\", 0.0),\n",
        "        \"year\": state[\"year\"],\n",
        "        \"driver_skill\": driver_skill_map.get(state[\"driver_id\"], 0.0),\n",
        "    }\n",
        "    num = scaler.transform(pd.DataFrame([row], columns=feature_cols))[0].astype(np.float32)\n",
        "    tyre_idx = compound2idx.get(state[\"tyre_compound\"], 0)\n",
        "    return num, tyre_idx\n",
        "\n",
        "\n",
        "def simulate_race(\n",
        "    model,\n",
        "    circuit_id,\n",
        "    grid_drivers,\n",
        "    total_laps=50,\n",
        "    year=2025,\n",
        "    global_strategy=None,\n",
        "    driver_strategies=None,\n",
        "    safety_car_laps=None,\n",
        "    rain_laps=None,\n",
        "    pit_loss=20.0,\n",
        "):\n",
        "    if global_strategy is None:\n",
        "        global_strategy = [(int(total_laps * 0.4), \"MEDIUM\"), (int(total_laps * 0.7), \"SOFT\")]\n",
        "    if driver_strategies is None:\n",
        "        driver_strategies = {}\n",
        "    safety_car_laps = set(safety_car_laps or [])\n",
        "    rain_laps = set(rain_laps or [])\n",
        "\n",
        "    base_lap = circuit_median_map.get(circuit_id)\n",
        "    if base_lap is None:\n",
        "        raise ValueError(f\"No circuit_median_lap for circuit_id={circuit_id}\")\n",
        "    circuit_idx = circuit2idx.get(circuit_id, 0)\n",
        "\n",
        "    grid_pos_map = {drv: idx + 1 for idx, drv in enumerate(grid_drivers)}\n",
        "\n",
        "    driver_states = []\n",
        "    for idx, drv in enumerate(grid_drivers):\n",
        "        strat = driver_strategies.get(drv, global_strategy)\n",
        "        stops_map = {int(lap): compound for lap, compound in strat}\n",
        "        state = {\n",
        "            \"driver_id\": drv,\n",
        "            \"driver_idx\": driver2idx.get(drv, 0),\n",
        "            \"circuit_idx\": circuit_idx,\n",
        "            \"grid_position\": idx + 1,\n",
        "            \"position\": idx + 1,\n",
        "            \"cumul_time\": float(idx * 0.3),\n",
        "            \"laps_on_current_tyre\": 1,\n",
        "            \"tyre_compound\": \"SOFT\",\n",
        "            \"gap_to_ahead\": 0.0,\n",
        "            \"stops\": stops_map,\n",
        "            \"history\": [],\n",
        "            \"year\": year,\n",
        "            \"feature_history_num\": deque(maxlen=seq_len),\n",
        "            \"feature_history_tyre\": deque(maxlen=seq_len),\n",
        "        }\n",
        "        num_vec, tyre_idx = build_feature_vector(state, lap=1, total_laps=total_laps, safety_car_laps=safety_car_laps, rain_laps=rain_laps)\n",
        "        for _ in range(seq_len):\n",
        "            state[\"feature_history_num\"].append(num_vec)\n",
        "            state[\"feature_history_tyre\"].append(tyre_idx)\n",
        "        driver_states.append(state)\n",
        "\n",
        "    race_log = []\n",
        "\n",
        "    for lap in range(1, total_laps + 1):\n",
        "        prev_positions = {s[\"driver_id\"]: s[\"position\"] for s in driver_states}\n",
        "        drivers_by_pos = sorted(driver_states, key=lambda s: s[\"position\"])\n",
        "\n",
        "        for idx, s in enumerate(drivers_by_pos):\n",
        "            if idx == 0:\n",
        "                s[\"gap_to_ahead\"] = 0.0\n",
        "            else:\n",
        "                ahead = drivers_by_pos[idx - 1]\n",
        "                s[\"gap_to_ahead\"] = s[\"cumul_time\"] - ahead[\"cumul_time\"]\n",
        "\n",
        "        lap_times = []\n",
        "        pred_deltas = []\n",
        "        for s in drivers_by_pos:\n",
        "            num_vec, tyre_idx = build_feature_vector(\n",
        "                s, lap=lap, total_laps=total_laps, safety_car_laps=safety_car_laps, rain_laps=rain_laps\n",
        "            )\n",
        "            s[\"feature_history_num\"].append(num_vec)\n",
        "            s[\"feature_history_tyre\"].append(tyre_idx)\n",
        "            hist_num = np.stack(s[\"feature_history_num\"])[-seq_len:]\n",
        "            hist_tyre = np.array(s[\"feature_history_tyre\"])[-seq_len:]\n",
        "            delta = predict_delta_from_history(model, hist_num, hist_tyre, s[\"driver_idx\"], s[\"circuit_idx\"])\n",
        "            lap_time = base_lap + delta\n",
        "            lap_times.append(lap_time)\n",
        "            pred_deltas.append(delta)\n",
        "\n",
        "        lap_times, pred_deltas, overtake_attempts = apply_overtakes_for_lap(\n",
        "            circuit_id=circuit_id,\n",
        "            drivers_by_pos=drivers_by_pos,\n",
        "            lap_times=lap_times,\n",
        "            pred_deltas=pred_deltas,\n",
        "            base_lap=base_lap,\n",
        "            circuit_overtake_ease=circuit_overtake_ease,\n",
        "            close_gap_threshold=1.0,\n",
        "            fail_gap=0.3,\n",
        "        )\n",
        "\n",
        "        attempts_this_lap = {drivers_by_pos[i][\"driver_id\"]: bool(overtake_attempts[i]) for i in range(len(drivers_by_pos))}\n",
        "\n",
        "        for idx, s in enumerate(drivers_by_pos):\n",
        "            lap_time = float(lap_times[idx])\n",
        "            delta = float(pred_deltas[idx])\n",
        "            laps_on_current_tyre_next = s[\"laps_on_current_tyre\"] + 1\n",
        "            compound_this_lap = s[\"tyre_compound\"]\n",
        "            pit_compound = s[\"stops\"].get(lap)\n",
        "            pitted = False\n",
        "            if pit_compound is not None:\n",
        "                lap_time += pit_loss\n",
        "                pitted = True\n",
        "\n",
        "            s[\"laps_on_current_tyre\"] = laps_on_current_tyre_next\n",
        "            s[\"cumul_time\"] += lap_time\n",
        "            s[\"history\"].append(\n",
        "                {\n",
        "                    \"lap\": lap,\n",
        "                    \"lap_time\": lap_time,\n",
        "                    \"delta\": delta,\n",
        "                    \"tyre_compound\": compound_this_lap,\n",
        "                    \"pitted\": pitted,\n",
        "                    \"overtake_attempt\": attempts_this_lap.get(s[\"driver_id\"], False),\n",
        "                }\n",
        "            )\n",
        "\n",
        "            if pit_compound is not None:\n",
        "                s[\"tyre_compound\"] = pit_compound\n",
        "                s[\"laps_on_current_tyre\"] = 1\n",
        "\n",
        "        driver_states = sorted(driver_states, key=lambda s: (s[\"cumul_time\"], s[\"grid_position\"]))\n",
        "        for pos, s in enumerate(driver_states, start=1):\n",
        "            s[\"position\"] = pos\n",
        "\n",
        "        leader_time = driver_states[0][\"cumul_time\"]\n",
        "        for s in driver_states:\n",
        "            last_lap = s[\"history\"][-1]\n",
        "            gap_to_leader = s[\"cumul_time\"] - leader_time\n",
        "            pos_change = prev_positions[s[\"driver_id\"]] - s[\"position\"]\n",
        "            race_log.append(\n",
        "                {\n",
        "                    \"lap\": lap,\n",
        "                    \"position\": s[\"position\"],\n",
        "                    \"driver_id\": s[\"driver_id\"],\n",
        "                    \"lap_time\": last_lap[\"lap_time\"],\n",
        "                    \"delta\": last_lap[\"delta\"],\n",
        "                    \"tyre_compound\": last_lap[\"tyre_compound\"],\n",
        "                    \"pitted\": last_lap[\"pitted\"],\n",
        "                    \"gap_to_leader\": gap_to_leader,\n",
        "                    \"cumul_time\": s[\"cumul_time\"],\n",
        "                    \"overtake_attempt\": last_lap[\"overtake_attempt\"],\n",
        "                    \"pos_change_lap\": pos_change,\n",
        "                    \"pos_change_total\": grid_pos_map[s[\"driver_id\"]] - s[\"position\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "    print(\"Final classification\")\n",
        "    for s in driver_states:\n",
        "        total_change = grid_pos_map[s[\"driver_id\"]] - s[\"position\"]\n",
        "        print(\n",
        "            f\"P{s['position']:2d} {s['driver_id']:3s} total {format_seconds(s['cumul_time'])} \"\n",
        "            f\"(grid {grid_pos_map[s['driver_id']]:2d}, {total_change:+d})\"\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame(race_log)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "03b463fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Circuit: austin Grid size: 20\n",
            "Final classification\n",
            "P 1 VER total 21:35.00 (grid  1, +0)\n",
            "P 2 LEC total 21:39.33 (grid  2, +0)\n",
            "P 3 HAM total 21:47.67 (grid  4, +1)\n",
            "P 4 SAI total 21:54.71 (grid  9, +5)\n",
            "P 5 PIA total 21:55.01 (grid  5, +0)\n",
            "P 6 TSU total 21:57.32 (grid 10, +4)\n",
            "P 7 ANT total 22:00.36 (grid  7, +0)\n",
            "P 8 BEA total 22:04.84 (grid  8, +0)\n",
            "P 9 ALO total 22:05.85 (grid 12, +3)\n",
            "P10 NOR total 22:06.86 (grid  3, -7)\n",
            "P11 HUL total 22:07.40 (grid 11, +0)\n",
            "P12 RUS total 22:07.70 (grid  6, -6)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lap</th>\n",
              "      <th>position</th>\n",
              "      <th>driver_id</th>\n",
              "      <th>lap_time</th>\n",
              "      <th>delta</th>\n",
              "      <th>tyre_compound</th>\n",
              "      <th>pitted</th>\n",
              "      <th>gap_to_leader</th>\n",
              "      <th>cumul_time</th>\n",
              "      <th>overtake_attempt</th>\n",
              "      <th>pos_change_lap</th>\n",
              "      <th>pos_change_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>VER</td>\n",
              "      <td>98.576410</td>\n",
              "      <td>-2.940590</td>\n",
              "      <td>SOFT</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.576410</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>LEC</td>\n",
              "      <td>99.519795</td>\n",
              "      <td>-1.997205</td>\n",
              "      <td>SOFT</td>\n",
              "      <td>False</td>\n",
              "      <td>1.243385</td>\n",
              "      <td>99.819795</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NOR</td>\n",
              "      <td>99.519795</td>\n",
              "      <td>-1.997205</td>\n",
              "      <td>SOFT</td>\n",
              "      <td>False</td>\n",
              "      <td>1.543385</td>\n",
              "      <td>100.119795</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>HAM</td>\n",
              "      <td>99.519795</td>\n",
              "      <td>-1.997205</td>\n",
              "      <td>SOFT</td>\n",
              "      <td>False</td>\n",
              "      <td>1.843385</td>\n",
              "      <td>100.419795</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>PIA</td>\n",
              "      <td>99.519795</td>\n",
              "      <td>-1.997205</td>\n",
              "      <td>SOFT</td>\n",
              "      <td>False</td>\n",
              "      <td>2.143385</td>\n",
              "      <td>100.719795</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lap  position driver_id   lap_time     delta tyre_compound  pitted  \\\n",
              "0    1         1       VER  98.576410 -2.940590          SOFT   False   \n",
              "1    1         2       LEC  99.519795 -1.997205          SOFT   False   \n",
              "2    1         3       NOR  99.519795 -1.997205          SOFT   False   \n",
              "3    1         4       HAM  99.519795 -1.997205          SOFT   False   \n",
              "4    1         5       PIA  99.519795 -1.997205          SOFT   False   \n",
              "\n",
              "   gap_to_leader  cumul_time  overtake_attempt  pos_change_lap  \\\n",
              "0       0.000000   98.576410             False               0   \n",
              "1       1.243385   99.819795              True               0   \n",
              "2       1.543385  100.119795              True               0   \n",
              "3       1.843385  100.419795              True               0   \n",
              "4       2.143385  100.719795              True               0   \n",
              "\n",
              "   pos_change_total  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example: build a grid from the latest session and simulate a short race\n",
        "lap1_rows = df_model[df_model[\"lap_number\"] == 1]\n",
        "if lap1_rows.empty:\n",
        "    raise ValueError(\"No lap_number == 1 rows available to build a grid.\")\n",
        "\n",
        "last_row = lap1_rows.iloc[-1]\n",
        "session_key = last_row[\"session_key\"]\n",
        "session_lap1 = lap1_rows[lap1_rows[\"session_key\"] == session_key].copy().sort_values(\"current_position\")\n",
        "\n",
        "grid_drivers = list(session_lap1[\"driver_id\"])\n",
        "circuit_id = last_row[\"circuit_id\"]\n",
        "total_laps = int(session_lap1[\"total_race_laps\"].iloc[0]) if not session_lap1[\"total_race_laps\"].isna().all() else 50\n",
        "\n",
        "print(\"Circuit:\", circuit_id, \"Grid size:\", len(grid_drivers))\n",
        "\n",
        "race_df_sim = simulate_race(\n",
        "    model,\n",
        "    circuit_id=circuit_id,\n",
        "    grid_drivers=grid_drivers[:12],  # keep short for demo\n",
        "    total_laps=min(12, total_laps),\n",
        "    year=int(last_row[\"year\"]),\n",
        "    global_strategy=[(int(total_laps * 0.4), \"MEDIUM\"), (int(total_laps * 0.8), \"SOFT\")],\n",
        "    safety_car_laps=[5],\n",
        "    rain_laps=[],\n",
        "    pit_loss=22.0,\n",
        ")\n",
        "\n",
        "race_df_sim.head()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
