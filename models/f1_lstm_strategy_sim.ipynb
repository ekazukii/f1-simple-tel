{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "F1 LSTM Strategy Simulator\n",
    "==========================\n",
    "\n",
    "This module trains an LSTM model on lap-by-lap data to predict lap times,\n",
    "then simulates races given user strategies (pits, compounds), safety cars, DNFs, and weather.\n",
    "\n",
    "It auto-detects column names commonly found in FastF1 exports, builds variable-length sequences\n",
    "per driver per race, and uses masked LSTM training.\n",
    "\n",
    "Dependencies:\n",
    "- pandas, numpy, scikit-learn, joblib\n",
    "- tensorflow>=2.9 (Keras)\n",
    "\n",
    "Usage\n",
    "-----\n",
    "Train:\n",
    "  python f1_lstm_strategy_sim.py --csv /path/to/fastf1_lap_dataset.csv --train --save_dir /path/to/f1_lstm_model\n",
    "\n",
    "Simulate with a trained model:\n",
    "  python f1_lstm_strategy_sim.py --csv /path/to/fastf1_lap_dataset.csv --load_dir /path/to/f1_lstm_model --demo\n",
    "\n",
    "Programmatic:\n",
    "  from f1_lstm_strategy_sim import LSTMLapTimeModel, LSTMSimulator, RaceConfig, DriverSpec, PitEvent\n",
    "  model = LSTMLapTimeModel().fit_from_csv(csv_path)\n",
    "  sim = LSTMSimulator(model)\n",
    "  result = sim.simulate(config)\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- Pit laps are excluded from training. The simulator adds pit loss time explicitly.\n",
    "- Safety car laps are included in training so the model learns the pace reduction when is_sc=True.\n",
    "- Unseen categorical values are mapped to a special \"UNK\" token at inference time.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b938885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (2.20.0)\n",
      "Requirement already satisfied: numpy in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (1.5.2)\n",
      "Requirement already satisfied: keras in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (3.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: packaging in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: rich in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from keras) (14.2.0)\n",
      "Requirement already satisfied: namex in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from keras) (0.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pillow in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (3.23.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ekazuki/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow numpy pandas scikit-learn joblib keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00723bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekazuki/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Column detection\n",
    "# -----------------------------\n",
    "\n",
    "CANDIDATES = {\n",
    "    \"driver\": [\"driver\", \"Driver\", \"DriverRef\", \"DriverId\", \"driver_id\", \"DriverNumber\", \"DriverCode\"],\n",
    "    \"team\": [\"team\", \"Team\", \"Constructor\", \"constructor_name\", \"ConstructorRef\", \"ConstructorId\"],\n",
    "    \"circuit\": [\"circuit\", \"Circuit\", \"track\", \"Track\", \"EventName\", \"race_name\", \"RaceName\", \"CircuitName\"],\n",
    "    \"session_key\": [\"SessionKey\", \"session_key\", \"raceId\", \"RaceId\"],\n",
    "    \"lap_number\": [\"lap\", \"Lap\", \"LapNo\", \"LapNumber\", \"lap_number\"],\n",
    "    \"lap_time_s\": [\"lap_time_s\", \"LapTimeSeconds\", \"LapTime_Sec\", \"LapTimeSec\", \"LapTimeSecondsFloat\"],\n",
    "    \"lap_time_ms\": [\"LapTimeMillis\", \"lap_time_ms\", \"LapTimeMs\"],\n",
    "    \"lap_time_str\": [\"LapTime\", \"Time\", \"LapTimeString\"],\n",
    "    \"compound\": [\"compound\", \"Compound\", \"Tyre\", \"TyreCompound\", \"tyre_compound\"],\n",
    "    \"tyre_age\": [\"tyre_age\", \"TyreLife\", \"LapsSincePit\", \"laps_on_current_tyre\", \"StintLap\", \"TyreAge\", \"TyreLap\"],\n",
    "    \"position\": [\"Position\", \"position\", \"PositionOrder\", \"CurrentPosition\"],\n",
    "    \"gap_to_ahead\": [\"GapToAhead\", \"gap_to_ahead_s\", \"GapAheadSec\"],\n",
    "    \"air_temp\": [\"air_temp\", \"AirTemp\", \"AirTemperature\"],\n",
    "    \"track_temp\": [\"track_temp\", \"TrackTemp\", \"TrackTemperature\"],\n",
    "    \"humidity\": [\"humidity\", \"Humidity\"],\n",
    "    \"wind_speed\": [\"wind_speed\", \"WindSpeed\"],\n",
    "    \"wind_dir\": [\"wind_direction\", \"WindDirection\"],\n",
    "    \"rain\": [\"is_rain\", \"Rain\", \"Rainfall\", \"RainfallMm\"],\n",
    "    \"track_status\": [\"TrackStatus\", \"track_status\"],\n",
    "    \"is_sc\": [\"is_sc\", \"SafetyCar\", \"SC\", \"sc_lap\"],\n",
    "    \"is_vsc\": [\"is_vsc\", \"VirtualSafetyCar\", \"VSC\", \"vsc_lap\"],\n",
    "}\n",
    "\n",
    "def find_col(df: pd.DataFrame, keys: List[str]) -> Optional[str]:\n",
    "    cols = set(df.columns)\n",
    "    for k in keys:\n",
    "        if k in cols:\n",
    "            return k\n",
    "    # case-insensitive\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for k in keys:\n",
    "        if k.lower() in low:\n",
    "            return low[k.lower()]\n",
    "    return None\n",
    "\n",
    "def parse_lap_time_str_to_seconds(s: str) -> Optional[float]:\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    try:\n",
    "        if \":\" in s:\n",
    "            m, sec = s.split(\":\")\n",
    "            return int(m) * 60.0 + float(sec)\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fd4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare(csv_path: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    mapping = {}\n",
    "\n",
    "    for key in [\"driver\",\"team\",\"circuit\",\"session_key\",\"lap_number\",\"compound\"]:\n",
    "        mapping[key] = find_col(df, CANDIDATES[key])\n",
    "\n",
    "    # lap time\n",
    "    lap_time_col = find_col(df, CANDIDATES[\"lap_time_s\"])\n",
    "    if lap_time_col is None:\n",
    "        lt_ms = find_col(df, CANDIDATES[\"lap_time_ms\"])\n",
    "        if lt_ms is not None:\n",
    "            df[\"lap_time_s_auto\"] = df[lt_ms] / 1000.0\n",
    "            lap_time_col = \"lap_time_s_auto\"\n",
    "        else:\n",
    "            lt_str = find_col(df, CANDIDATES[\"lap_time_str\"])\n",
    "            if lt_str is not None:\n",
    "                df[\"lap_time_s_auto\"] = df[lt_str].apply(parse_lap_time_str_to_seconds)\n",
    "                lap_time_col = \"lap_time_s_auto\"\n",
    "    if lap_time_col is None:\n",
    "        raise ValueError(\"No lap time column found\")\n",
    "    mapping[\"lap_time_s\"] = lap_time_col\n",
    "\n",
    "    # optional numeric\n",
    "    for key in [\"tyre_age\",\"position\",\"gap_to_ahead\",\"air_temp\",\"track_temp\",\"humidity\",\"wind_speed\",\"wind_dir\",\"rain\",\"track_status\",\"is_sc\",\"is_vsc\"]:\n",
    "        mapping[key] = find_col(df, CANDIDATES[key])\n",
    "\n",
    "    # clean\n",
    "    # numeric conversion for lap number\n",
    "    if mapping[\"lap_number\"] is not None:\n",
    "        df[mapping[\"lap_number\"]] = pd.to_numeric(df[mapping[\"lap_number\"]], errors=\"coerce\")\n",
    "\n",
    "    # derive tyre age if missing\n",
    "    if mapping[\"tyre_age\"] is None and mapping[\"driver\"] and mapping[\"circuit\"] and mapping[\"lap_number\"]:\n",
    "        df = df.sort_values([mapping[\"driver\"], mapping[\"circuit\"], mapping[\"lap_number\"]])\n",
    "        ages = []\n",
    "        last_cmpd = {}\n",
    "        for idx, r in df.iterrows():\n",
    "            key = (r[mapping[\"driver\"]], r[mapping[\"circuit\"]])\n",
    "            cmpd = r[mapping[\"compound\"]] if mapping[\"compound\"] else None\n",
    "            if key not in last_cmpd or last_cmpd[key] != cmpd:\n",
    "                ages.append(0)\n",
    "                last_cmpd[key] = cmpd\n",
    "            else:\n",
    "                ages.append( (ages[-1] if ages else 0) + 1 )\n",
    "        df[\"tyre_age_auto\"] = ages\n",
    "        mapping[\"tyre_age\"] = \"tyre_age_auto\"\n",
    "\n",
    "    # SC/VSC from track status if not present\n",
    "    if mapping[\"is_sc\"] is None and mapping[\"track_status\"] is not None:\n",
    "        ts = df[mapping[\"track_status\"]].astype(str)\n",
    "        df[\"is_sc_auto\"] = ts.str.contains(\"4\")\n",
    "        df[\"is_vsc_auto\"] = ts.str.contains(\"5\")\n",
    "        mapping[\"is_sc\"] = \"is_sc_auto\"\n",
    "        mapping[\"is_vsc\"] = \"is_vsc_auto\"\n",
    "\n",
    "    # rain to boolean if numeric\n",
    "    if mapping[\"rain\"] is not None and df[mapping[\"rain\"]].dtype.kind in \"iufc\":\n",
    "        df[\"is_rain_bool\"] = df[mapping[\"rain\"]].fillna(0) > 0\n",
    "        mapping[\"rain\"] = \"is_rain_bool\"\n",
    "\n",
    "    # filter lap times\n",
    "    lt = df[mapping[\"lap_time_s\"]]\n",
    "    df = df[(lt > 25) & (lt < 300)].copy()\n",
    "\n",
    "    # infer pit this lap\n",
    "    df[\"pit_this_lap\"] = False\n",
    "    if mapping[\"driver\"] and mapping[\"circuit\"] and mapping[\"lap_number\"]:\n",
    "        df = df.sort_values([mapping[\"driver\"], mapping[\"circuit\"], mapping[\"session_key\"] or mapping[\"circuit\"], mapping[\"lap_number\"]])\n",
    "        grp = df.groupby([c for c in [mapping[\"driver\"], mapping[\"circuit\"], mapping[\"session_key\"]] if c], sort=False)\n",
    "        if mapping[\"compound\"]:\n",
    "            df[\"comp_prev\"] = grp[mapping[\"compound\"]].shift(1)\n",
    "            df[\"pit_by_comp\"] = df[mapping[\"compound\"]] != df[\"comp_prev\"]\n",
    "        else:\n",
    "            df[\"pit_by_comp\"] = False\n",
    "        if mapping[\"tyre_age\"]:\n",
    "            df[\"age_prev\"] = grp[mapping[\"tyre_age\"]].shift(1)\n",
    "            df[\"pit_by_age\"] = df[mapping[\"tyre_age\"]] <= df[\"age_prev\"]\n",
    "        else:\n",
    "            df[\"pit_by_age\"] = False\n",
    "        df[\"pit_this_lap\"] = df[\"pit_by_comp\"].fillna(False) | df[\"pit_by_age\"].fillna(False)\n",
    "        df.drop(columns=[\"comp_prev\",\"age_prev\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    return df.reset_index(drop=True), mapping\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Sequence builder\n",
    "# -----------------------------\n",
    "\n",
    "NUMERIC_KEYS_ORDER = [\"lap_number\",\"tyre_age\",\"position\",\"gap_to_ahead\",\"air_temp\",\"track_temp\",\"humidity\",\"wind_speed\",\"is_sc\",\"is_vsc\",\"rain\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37811ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.mapping: Dict[str, str] = {}\n",
    "        self.cat_maps: Dict[str, Dict[str,int]] = {}\n",
    "        self.numeric_means: Dict[str, float] = {}\n",
    "        self.numeric_stds: Dict[str, float] = {}\n",
    "        self.num_cols: List[str] = []\n",
    "        self.cat_cols: List[str] = []\n",
    "        self.max_len: int = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_index(values: List[str]) -> Dict[str,int]:\n",
    "        # 0 is padding, 1 is UNK, others start at 2\n",
    "        uniq = [\"<PAD>\",\"<UNK>\"] + sorted([v for v in pd.unique(values) if pd.notna(v)])\n",
    "        return {v:i for i,v in enumerate(uniq)}\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, mapping: Dict[str,str]):\n",
    "        self.mapping = mapping\n",
    "        # categorical maps\n",
    "        cat_keys = [\"driver\",\"team\",\"circuit\",\"compound\"]\n",
    "        for k in cat_keys:\n",
    "            col = mapping.get(k)\n",
    "            if col is None:\n",
    "                # fallback single token\n",
    "                self.cat_maps[k] = {\"<PAD>\":0,\"<UNK>\":1,\"UNK\":2}\n",
    "            else:\n",
    "                self.cat_maps[k] = self._build_index(df[col].astype(str).tolist())\n",
    "        self.cat_cols = cat_keys\n",
    "\n",
    "        # numeric columns present\n",
    "        present = []\n",
    "        for k in NUMERIC_KEYS_ORDER:\n",
    "            col = mapping.get(k)\n",
    "            if col is not None and col in df:\n",
    "                present.append(k)\n",
    "        self.num_cols = present\n",
    "\n",
    "        # mean/std on non-pit rows\n",
    "        base = df[df[\"pit_this_lap\"] == False]\n",
    "        for k in self.num_cols:\n",
    "            col = mapping[k]\n",
    "            x = pd.to_numeric(base[col], errors=\"coerce\")\n",
    "            m = float(x.mean(skipna=True)) if x.notna().any() else 0.0\n",
    "            s = float(x.std(skipna=True)) if x.notna().any() else 1.0\n",
    "            if s == 0 or not np.isfinite(s):\n",
    "                s = 1.0\n",
    "            self.numeric_means[k] = m\n",
    "            self.numeric_stds[k] = s\n",
    "\n",
    "        # estimate max sequence length\n",
    "        group_cols = [c for c in [mapping.get(\"driver\"), mapping.get(\"circuit\"), mapping.get(\"session_key\")] if c]\n",
    "        if not group_cols:\n",
    "            group_cols = [mapping.get(\"driver\"), mapping.get(\"circuit\")]\n",
    "        counts = df[df[\"pit_this_lap\"] == False].groupby(group_cols).size()\n",
    "        self.max_len = int(counts.max()) if len(counts) else 60\n",
    "\n",
    "    def _idx(self, key: str, val: Any) -> int:\n",
    "        m = self.cat_maps[key]\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "            return 1  # UNK\n",
    "        s = str(val)\n",
    "        return m.get(s, 1)\n",
    "\n",
    "    def _num(self, key: str, val: Any) -> float:\n",
    "        if val is None or (isinstance(val, float) and not np.isfinite(val)):\n",
    "            val = self.numeric_means.get(key, 0.0)\n",
    "        col_mean = self.numeric_means.get(key, 0.0)\n",
    "        col_std = self.numeric_stds.get(key, 1.0)\n",
    "        return float((float(val) - col_mean) / col_std)\n",
    "\n",
    "    def build_group_sequences(self, df: pd.DataFrame) -> Tuple[Dict[str,np.ndarray], np.ndarray, List[int]]:\n",
    "        \"\"\"\n",
    "        Returns model inputs dict, targets array, and list of true lengths per sequence.\n",
    "        Sequences are built per (driver,circuit,session) with pit laps removed.\n",
    "        \"\"\"\n",
    "        mapping = self.mapping\n",
    "        group_cols = [c for c in [mapping.get(\"driver\"), mapping.get(\"circuit\"), mapping.get(\"session_key\")] if c]\n",
    "        if not group_cols:\n",
    "            group_cols = [mapping.get(\"driver\"), mapping.get(\"circuit\")]\n",
    "\n",
    "        # prepare groups\n",
    "        base = df[df[\"pit_this_lap\"] == False].copy()\n",
    "        if mapping.get(\"lap_number\") is not None:\n",
    "            base = base.sort_values(group_cols + [mapping[\"lap_number\"]])\n",
    "        else:\n",
    "            base = base.sort_values(group_cols)\n",
    "\n",
    "        seqs = []\n",
    "        yseqs = []\n",
    "        lengths = []\n",
    "\n",
    "        # arrays will be padded to max_len\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        for _, g in base.groupby(group_cols):\n",
    "            # drop rows without target\n",
    "            g = g[pd.notna(g[mapping[\"lap_time_s\"]])]\n",
    "            if g.empty:\n",
    "                continue\n",
    "\n",
    "            # Build per-timestep lists\n",
    "            drv_idx = [self._idx(\"driver\", v) for v in g[mapping[\"driver\"]].astype(str)]\n",
    "            team_idx = [self._idx(\"team\", v) for v in g[mapping[\"team\"]].astype(str)] if mapping.get(\"team\") else [self._idx(\"team\", \"UNK\")] * len(g)\n",
    "            circ_idx = [self._idx(\"circuit\", v) for v in g[mapping[\"circuit\"]].astype(str)]\n",
    "            comp_idx = [self._idx(\"compound\", v) for v in g[mapping[\"compound\"]].astype(str)] if mapping.get(\"compound\") else [self._idx(\"compound\", \"UNK\")] * len(g)\n",
    "\n",
    "            # numeric\n",
    "            num_steps = []\n",
    "            for _, r in g.iterrows():\n",
    "                step = []\n",
    "                for k in self.num_cols:\n",
    "                    col = mapping[k]\n",
    "                    step.append(self._num(k, r[col]))\n",
    "                num_steps.append(step)\n",
    "\n",
    "            y = g[mapping[\"lap_time_s\"]].astype(float).values\n",
    "\n",
    "            L = len(y)\n",
    "            lengths.append(L)\n",
    "\n",
    "            # pad\n",
    "            def pad_list(lst, pad_val):\n",
    "                return lst + [pad_val] * (maxlen - len(lst))\n",
    "\n",
    "            drv = pad_list(drv_idx, 0)\n",
    "            team = pad_list(team_idx, 0)\n",
    "            circ = pad_list(circ_idx, 0)\n",
    "            comp = pad_list(comp_idx, 0)\n",
    "            num = num_steps + [[0.0]*len(self.num_cols)] * (maxlen - len(num_steps))\n",
    "            ypad = list(y) + [0.0] * (maxlen - L)\n",
    "\n",
    "            seqs.append((drv, team, circ, comp, num))\n",
    "            yseqs.append(ypad)\n",
    "\n",
    "        if not seqs:\n",
    "            raise ValueError(\"No sequences built from dataset. Check column mappings.\")\n",
    "\n",
    "        drv_arr = np.array([s[0] for s in seqs], dtype=np.int32)\n",
    "        team_arr = np.array([s[1] for s in seqs], dtype=np.int32)\n",
    "        circ_arr = np.array([s[2] for s in seqs], dtype=np.int32)\n",
    "        comp_arr = np.array([s[3] for s in seqs], dtype=np.int32)\n",
    "        num_arr = np.array([s[4] for s in seqs], dtype=np.float32)\n",
    "        y_arr = np.array(yseqs, dtype=np.float32)\n",
    "\n",
    "        inputs = {\n",
    "            \"driver_seq\": drv_arr,\n",
    "            \"team_seq\": team_arr,\n",
    "            \"circuit_seq\": circ_arr,\n",
    "            \"compound_seq\": comp_arr,\n",
    "            \"num_seq\": num_arr,\n",
    "        }\n",
    "        return inputs, y_arr, lengths\n",
    "\n",
    "    # Build a single sequence from a history of dict steps (for inference in sim)\n",
    "    def build_single_inputs(self, hist_steps: List[Dict[str,Any]]) -> Dict[str,np.ndarray]:\n",
    "        maxlen = self.max_len\n",
    "        L = len(hist_steps)\n",
    "        L = min(L, maxlen)\n",
    "        steps = hist_steps[-L:]\n",
    "\n",
    "        def get_val(step, key):\n",
    "            # step keys are logical keys, not raw columns\n",
    "            return step.get(key, None)\n",
    "\n",
    "        drv_idx = [self._idx(\"driver\", get_val(s,\"driver\")) for s in steps]\n",
    "        team_idx = [self._idx(\"team\", get_val(s,\"team\")) for s in steps]\n",
    "        circ_idx = [self._idx(\"circuit\", get_val(s,\"circuit\")) for s in steps]\n",
    "        comp_idx = [self._idx(\"compound\", get_val(s,\"compound\")) for s in steps]\n",
    "\n",
    "        num_steps = []\n",
    "        for s in steps:\n",
    "            row = []\n",
    "            for k in self.num_cols:\n",
    "                row.append(self._num(k, get_val(s, k)))\n",
    "            num_steps.append(row)\n",
    "\n",
    "        # pad\n",
    "        drv = drv_idx + [0]*(maxlen - L)\n",
    "        team = team_idx + [0]*(maxlen - L)\n",
    "        circ = circ_idx + [0]*(maxlen - L)\n",
    "        comp = comp_idx + [0]*(maxlen - L)\n",
    "        num = num_steps + [[0.0]*len(self.num_cols)]*(maxlen - L)\n",
    "\n",
    "        inputs = {\n",
    "            \"driver_seq\": np.array([drv], dtype=np.int32),\n",
    "            \"team_seq\": np.array([team], dtype=np.int32),\n",
    "            \"circuit_seq\": np.array([circ], dtype=np.int32),\n",
    "            \"compound_seq\": np.array([comp], dtype=np.int32),\n",
    "            \"num_seq\": np.array([num], dtype=np.float32),\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26e0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(cat_maps: Dict[str,Dict[str,int]], num_dim: int, max_len: int) -> keras.Model:\n",
    "    # Inputs\n",
    "    driver_in = keras.Input(shape=(max_len,), dtype=\"int32\", name=\"driver_seq\")\n",
    "    team_in = keras.Input(shape=(max_len,), dtype=\"int32\", name=\"team_seq\")\n",
    "    circuit_in = keras.Input(shape=(max_len,), dtype=\"int32\", name=\"circuit_seq\")\n",
    "    compound_in = keras.Input(shape=(max_len,), dtype=\"int32\", name=\"compound_seq\")\n",
    "    num_in = keras.Input(shape=(max_len, num_dim), dtype=\"float32\", name=\"num_seq\")\n",
    "\n",
    "    # Embeddings with mask_zero=True to mask padding=0\n",
    "    def emb(name, vocab):\n",
    "        vocab_size = len(vocab)\n",
    "        dim = min(32, max(8, vocab_size // 8))\n",
    "        return layers.Embedding(vocab_size, dim, mask_zero=True, name=f\"{name}_emb\")\n",
    "\n",
    "    drv_emb = emb(\"driver\", cat_maps[\"driver\"])(driver_in)\n",
    "    team_emb = emb(\"team\", cat_maps[\"team\"])(team_in)\n",
    "    circ_emb = emb(\"circuit\", cat_maps[\"circuit\"])(circuit_in)\n",
    "    comp_emb = emb(\"compound\", cat_maps[\"compound\"])(compound_in)\n",
    "\n",
    "    # Concatenate embeddings and numeric\n",
    "    x = layers.Concatenate()([drv_emb, team_emb, circ_emb, comp_emb, num_in])\n",
    "\n",
    "    # LSTM stack\n",
    "    x = layers.Masking(mask_value=0.0)(x)  # extra safety for numeric zeros\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "    x = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(x)\n",
    "    out = layers.TimeDistributed(layers.Dense(1, activation=\"linear\"), name=\"y\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[driver_in, team_in, circuit_in, compound_in, num_in], outputs=out)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mae\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9c3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLapTimeModel:\n",
    "    def __init__(self):\n",
    "        self.prep = SeqPreprocessor()\n",
    "        self.model: Optional[keras.Model] = None\n",
    "        self.mapping: Dict[str,str] = {}\n",
    "        self.pit_loss_by_circuit: Dict[str,float] = {}\n",
    "\n",
    "    def fit_from_csv(self, csv_path: str, val_size: float=0.15, random_state: int=42, epochs: int=20, batch_size: int=32):\n",
    "        df, mapping = load_and_prepare(csv_path)\n",
    "        self.mapping = mapping\n",
    "\n",
    "        # estimate pit loss per circuit for simulator\n",
    "        self.pit_loss_by_circuit = self._estimate_pit_loss(df, mapping)\n",
    "\n",
    "        self.prep.fit(df, mapping)\n",
    "        X, y, lengths = self.prep.build_group_sequences(df)\n",
    "\n",
    "        # train/val split by sequences\n",
    "        idx = np.arange(y.shape[0])\n",
    "        tr_idx, va_idx = train_test_split(idx, test_size=val_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "        def subset(X, idxs):\n",
    "            return {k: v[idxs] for k,v in X.items()}\n",
    "\n",
    "        X_tr, y_tr = subset(X, tr_idx), y[tr_idx]\n",
    "        X_va, y_va = subset(X, va_idx), y[va_idx]\n",
    "\n",
    "        model = build_lstm_model(self.prep.cat_maps, len(self.prep.num_cols), self.prep.max_len)\n",
    "        cb = [\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=4, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_mae\", factor=0.5, patience=2, min_lr=1e-5),\n",
    "        ]\n",
    "        model.fit(X_tr, y_tr[..., None], validation_data=(X_va, y_va[..., None]), epochs=epochs, batch_size=batch_size, verbose=2, callbacks=cb)\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def predict_sequence(self, steps: List[Dict[str,Any]]) -> np.ndarray:\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded or trained\")\n",
    "        X = self.prep.build_single_inputs(steps)\n",
    "        yhat = self.model.predict(X, verbose=0)\n",
    "        # return 1D array of predictions for each timestep, take last index as latest prediction\n",
    "        return yhat[0, :, 0]\n",
    "\n",
    "    def save(self, save_dir: str):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model to save\")\n",
    "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        # save keras model\n",
    "        self.model.save(str(Path(save_dir) / \"model.keras\"))\n",
    "        # save preprocessor and artifacts\n",
    "        payload = {\n",
    "            \"mapping\": self.prep.mapping,\n",
    "            \"cat_maps\": self.prep.cat_maps,\n",
    "            \"numeric_means\": self.prep.numeric_means,\n",
    "            \"numeric_stds\": self.prep.numeric_stds,\n",
    "            \"num_cols\": self.prep.num_cols,\n",
    "            \"cat_cols\": self.prep.cat_cols,\n",
    "            \"max_len\": self.prep.max_len,\n",
    "            \"pit_loss_by_circuit\": self.pit_loss_by_circuit,\n",
    "        }\n",
    "        joblib.dump(payload, str(Path(save_dir) / \"prep.joblib\"))\n",
    "\n",
    "    def load(self, load_dir: str):\n",
    "        self.model = keras.models.load_model(str(Path(load_dir) / \"model.keras\"))\n",
    "        payload = joblib.load(str(Path(load_dir) / \"prep.joblib\"))\n",
    "        self.prep = SeqPreprocessor()\n",
    "        self.prep.mapping = payload[\"mapping\"]\n",
    "        self.prep.cat_maps = payload[\"cat_maps\"]\n",
    "        self.prep.numeric_means = payload[\"numeric_means\"]\n",
    "        self.prep.numeric_stds = payload[\"numeric_stds\"]\n",
    "        self.prep.num_cols = payload[\"num_cols\"]\n",
    "        self.prep.cat_cols = payload[\"cat_cols\"]\n",
    "        self.prep.max_len = payload[\"max_len\"]\n",
    "        self.mapping = self.prep.mapping\n",
    "        self.pit_loss_by_circuit = payload.get(\"pit_loss_by_circuit\", {})\n",
    "\n",
    "    def _estimate_pit_loss(self, df: pd.DataFrame, mapping: Dict[str,str]) -> Dict[str,float]:\n",
    "        circ_col = mapping.get(\"circuit\")\n",
    "        lt_col = mapping[\"lap_time_s\"]\n",
    "        pit_loss = {}\n",
    "        if circ_col is None:\n",
    "            return pit_loss\n",
    "        for circ, g in df.groupby(circ_col):\n",
    "            base = g[g[\"pit_this_lap\"] == False]\n",
    "            pits = g[g[\"pit_this_lap\"] == True]\n",
    "            if base.empty or pits.empty:\n",
    "                continue\n",
    "            med_base = base[lt_col].median()\n",
    "            loss = (pits[lt_col] - med_base).median()\n",
    "            if pd.notna(loss) and 5 < loss < 60:\n",
    "                pit_loss[str(circ)] = float(loss)\n",
    "        return pit_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ec0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DriverSpec:\n",
    "    name: str\n",
    "    team: str\n",
    "    grid: int\n",
    "    start_compound: str\n",
    "\n",
    "@dataclass\n",
    "class PitEvent:\n",
    "    lap: int\n",
    "    compound: str\n",
    "\n",
    "@dataclass\n",
    "class RaceConfig:\n",
    "    circuit: str\n",
    "    total_laps: int\n",
    "    drivers: List[DriverSpec]\n",
    "    strategy: Dict[str, List[PitEvent]] = field(default_factory=dict)\n",
    "    safety_cars: List[Tuple[int,int]] = field(default_factory=list)\n",
    "    dnfs: List[Tuple[str,int]] = field(default_factory=list)\n",
    "    weather_by_lap: Dict[int, Dict[str, Any]] = field(default_factory=dict)\n",
    "    default_weather: Dict[str, Any] = field(default_factory=dict)\n",
    "    default_pit_loss: float = 22.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ab4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSimulator:\n",
    "    def __init__(self, model: LSTMLapTimeModel):\n",
    "        if model.model is None:\n",
    "            raise ValueError(\"Provide a trained/loaded LSTMLapTimeModel\")\n",
    "        self.model = model\n",
    "\n",
    "    def _is_sc(self, lap: int, sc_windows: List[Tuple[int,int]]) -> bool:\n",
    "        for a,b in sc_windows:\n",
    "            if a <= lap <= b:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def simulate(self, config: RaceConfig) -> Dict[str, Any]:\n",
    "        prep = self.model.prep\n",
    "        pit_loss = self.model.pit_loss_by_circuit.get(config.circuit, config.default_pit_loss)\n",
    "\n",
    "        # State per driver\n",
    "        state = {}\n",
    "        history = {}\n",
    "        for d in config.drivers:\n",
    "            state[d.name] = {\n",
    "                \"team\": d.team,\n",
    "                \"compound\": d.start_compound,\n",
    "                \"tyre_age\": 0,\n",
    "                \"total_time\": 0.0,\n",
    "                \"grid\": d.grid,\n",
    "                \"running\": True,\n",
    "            }\n",
    "            history[d.name] = []\n",
    "\n",
    "        order = sorted([d.name for d in config.drivers], key=lambda n: state[n][\"grid\"])\n",
    "\n",
    "        # timeline\n",
    "        timeline = []\n",
    "\n",
    "        for lap in range(1, config.total_laps + 1):\n",
    "            # DNFs\n",
    "            for name, lap_dnf in config.dnfs:\n",
    "                if lap_dnf == lap and state.get(name) and state[name][\"running\"]:\n",
    "                    state[name][\"running\"] = False\n",
    "\n",
    "            is_sc = self._is_sc(lap, config.safety_cars)\n",
    "\n",
    "            # Build features per driver and predict lap times\n",
    "            lap_times = {}\n",
    "            for name in order:\n",
    "                s = state[name]\n",
    "                if not s[\"running\"]:\n",
    "                    continue\n",
    "\n",
    "                will_pit = any(e.lap == lap for e in config.strategy.get(name, []))\n",
    "\n",
    "                # Build current step logical features\n",
    "                step = {\n",
    "                    \"driver\": name,\n",
    "                    \"team\": s[\"team\"],\n",
    "                    \"circuit\": config.circuit,\n",
    "                    \"compound\": s[\"compound\"],\n",
    "                    \"lap_number\": lap,\n",
    "                    \"tyre_age\": s[\"tyre_age\"],\n",
    "                    \"is_sc\": 1 if is_sc else 0,\n",
    "                    \"is_vsc\": 0,\n",
    "                    \"rain\": 1 if bool(config.default_weather.get(\"rain\", False)) else 0,\n",
    "                    \"air_temp\": config.default_weather.get(\"air_temp\"),\n",
    "                    \"track_temp\": config.default_weather.get(\"track_temp\"),\n",
    "                    \"humidity\": config.default_weather.get(\"humidity\"),\n",
    "                    \"wind_speed\": config.default_weather.get(\"wind_speed\"),\n",
    "                    # traffic features can be added here if available\n",
    "                }\n",
    "                if lap in config.weather_by_lap:\n",
    "                    for k, v in config.weather_by_lap[lap].items():\n",
    "                        step[k] = v\n",
    "\n",
    "                # History + current step for sequence prediction\n",
    "                hist = history[name] + [step]\n",
    "                yhat_seq = self.model.predict_sequence(hist)\n",
    "                yhat = float(yhat_seq[len(hist)-1])  # last step prediction\n",
    "\n",
    "                if will_pit:\n",
    "                    yhat += pit_loss\n",
    "\n",
    "                lap_times[name] = yhat\n",
    "\n",
    "            # update totals\n",
    "            for name, t in lap_times.items():\n",
    "                state[name][\"total_time\"] += t\n",
    "\n",
    "            # update tyres and compounds\n",
    "            for name in order:\n",
    "                s = state[name]\n",
    "                if not s[\"running\"]:\n",
    "                    continue\n",
    "                if any(e.lap == lap for e in config.strategy.get(name, [])):\n",
    "                    # change compound\n",
    "                    new_c = [e.compound for e in config.strategy[name] if e.lap == lap][0]\n",
    "                    s[\"compound\"] = new_c\n",
    "                    s[\"tyre_age\"] = 0\n",
    "                else:\n",
    "                    s[\"tyre_age\"] += 1\n",
    "\n",
    "            # push current step to history\n",
    "            for name in order:\n",
    "                s = state[name]\n",
    "                if not s[\"running\"]:\n",
    "                    continue\n",
    "                # The step we added above had all needed features; append it now\n",
    "                # Ensure compound and tyre_age reflect post-lap state for next iteration\n",
    "                hist_step = {\n",
    "                    \"driver\": name,\n",
    "                    \"team\": s[\"team\"],\n",
    "                    \"circuit\": config.circuit,\n",
    "                    \"compound\": s[\"compound\"],\n",
    "                    \"lap_number\": lap,\n",
    "                    \"tyre_age\": s[\"tyre_age\"],\n",
    "                    \"is_sc\": 1 if is_sc else 0,\n",
    "                    \"is_vsc\": 0,\n",
    "                    \"rain\": 1 if bool(config.default_weather.get(\"rain\", False)) else 0,\n",
    "                    \"air_temp\": config.default_weather.get(\"air_temp\"),\n",
    "                    \"track_temp\": config.default_weather.get(\"track_temp\"),\n",
    "                    \"humidity\": config.default_weather.get(\"humidity\"),\n",
    "                    \"wind_speed\": config.default_weather.get(\"wind_speed\"),\n",
    "                }\n",
    "                if lap in config.weather_by_lap:\n",
    "                    for k, v in config.weather_by_lap[lap].items():\n",
    "                        hist_step[k] = v\n",
    "                history[name].append(hist_step)\n",
    "                # trim history to max_len\n",
    "                history[name] = history[name][-self.model.prep.max_len:]\n",
    "\n",
    "            # reorder by total_time\n",
    "            running = [n for n in order if state[n][\"running\"]]\n",
    "            running_sorted = sorted(running, key=lambda n: state[n][\"total_time\"])\n",
    "            dnfs = [n for n in order if not state[n][\"running\"]]\n",
    "            order = running_sorted + dnfs\n",
    "\n",
    "            timeline.append({\n",
    "                \"lap\": lap,\n",
    "                \"order\": running_sorted.copy(),\n",
    "                \"lap_times\": lap_times.copy(),\n",
    "                \"is_sc\": is_sc\n",
    "            })\n",
    "\n",
    "        # final classification\n",
    "        classification = []\n",
    "        pos = 1\n",
    "        for name in order:\n",
    "            s = state[name]\n",
    "            if s[\"running\"]:\n",
    "                classification.append({\"pos\": pos, \"driver\": name, \"team\": s[\"team\"], \"total_time\": s[\"total_time\"], \"status\": \"Finished\"})\n",
    "                pos += 1\n",
    "        for name in order:\n",
    "            s = state[name]\n",
    "            if not s[\"running\"]:\n",
    "                classification.append({\"pos\": None, \"driver\": name, \"team\": s[\"team\"], \"total_time\": s[\"total_time\"], \"status\": \"DNF\"})\n",
    "\n",
    "        return {\n",
    "            \"classification\": classification,\n",
    "            \"timeline\": timeline,\n",
    "            \"pit_loss_used\": pit_loss,\n",
    "        }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Demo utilities\n",
    "# -----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cbefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_config_from_dataset(df: pd.DataFrame, mapping: Dict[str,str]) -> RaceConfig:\n",
    "    circ_col = mapping.get(\"circuit\")\n",
    "    if circ_col is None:\n",
    "        raise ValueError(\"Circuit column missing\")\n",
    "    circuit = df[circ_col].dropna().astype(str).mode().iloc[0]\n",
    "\n",
    "    drv_col = mapping.get(\"driver\")\n",
    "    team_col = mapping.get(\"team\")\n",
    "    cmp_col = mapping.get(\"compound\")\n",
    "    lap_col = mapping.get(\"lap_number\")\n",
    "\n",
    "    sub = df[df[circ_col] == circuit].copy()\n",
    "    if lap_col in sub:\n",
    "        sub = sub.sort_values(lap_col)\n",
    "    first = sub.groupby(drv_col).first()\n",
    "    drivers = []\n",
    "    for i, (drv, row) in enumerate(first.head(10).iterrows(), start=1):\n",
    "        team = str(row[team_col]) if team_col else \"Team\"\n",
    "        comp = str(row[cmp_col]) if cmp_col else \"Medium\"\n",
    "        drivers.append(DriverSpec(name=str(drv), team=team, grid=i, start_compound=comp))\n",
    "\n",
    "    total_laps = int(sub[lap_col].max()) if lap_col is not None and pd.notna(sub[lap_col].max()) else 50\n",
    "\n",
    "    def med(col, default=None):\n",
    "        if mapping.get(col) and mapping[col] in sub:\n",
    "            v = sub[mapping[col]].median()\n",
    "            return float(v) if pd.notna(v) else default\n",
    "        return default\n",
    "\n",
    "    default_weather = {\n",
    "        \"air_temp\": med(\"air_temp\", 25.0),\n",
    "        \"track_temp\": med(\"track_temp\", 35.0),\n",
    "        \"humidity\": med(\"humidity\", 50.0),\n",
    "        \"wind_speed\": med(\"wind_speed\", 2.0),\n",
    "        \"rain\": False,\n",
    "    }\n",
    "\n",
    "    return RaceConfig(\n",
    "        circuit=str(circuit),\n",
    "        total_laps=total_laps,\n",
    "        drivers=drivers,\n",
    "        strategy={},\n",
    "        safety_cars=[],\n",
    "        dnfs=[],\n",
    "        weather_by_lap={},\n",
    "        default_weather=default_weather,\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CLI\n",
    "# -----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71a8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/lccpd1j15071g5nr0s6sjcr80000gn/T/ipykernel_68418/2132657337.py:14: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  uniq = [\"<PAD>\",\"<UNK>\"] + sorted([v for v in pd.unique(values) if pd.notna(v)])\n",
      "/var/folders/3t/lccpd1j15071g5nr0s6sjcr80000gn/T/ipykernel_68418/2132657337.py:14: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  uniq = [\"<PAD>\",\"<UNK>\"] + sorted([v for v in pd.unique(values) if pd.notna(v)])\n",
      "/var/folders/3t/lccpd1j15071g5nr0s6sjcr80000gn/T/ipykernel_68418/2132657337.py:14: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  uniq = [\"<PAD>\",\"<UNK>\"] + sorted([v for v in pd.unique(values) if pd.notna(v)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "86/86 - 6s - 72ms/step - loss: 29.6435 - mae: 29.6435 - val_loss: 6.3690 - val_mae: 6.3690 - learning_rate: 1.0000e-03\n",
      "Epoch 2/15\n",
      "86/86 - 2s - 19ms/step - loss: 3.8369 - mae: 3.8369 - val_loss: 2.4316 - val_mae: 2.4316 - learning_rate: 1.0000e-03\n",
      "Epoch 3/15\n",
      "86/86 - 2s - 19ms/step - loss: 2.2112 - mae: 2.2113 - val_loss: 2.1055 - val_mae: 2.1055 - learning_rate: 1.0000e-03\n",
      "Epoch 4/15\n",
      "86/86 - 2s - 19ms/step - loss: 2.0561 - mae: 2.0561 - val_loss: 2.0743 - val_mae: 2.0743 - learning_rate: 1.0000e-03\n",
      "Epoch 5/15\n",
      "86/86 - 2s - 19ms/step - loss: 1.9243 - mae: 1.9243 - val_loss: 1.9566 - val_mae: 1.9566 - learning_rate: 1.0000e-03\n",
      "Epoch 6/15\n",
      "86/86 - 2s - 19ms/step - loss: 1.8753 - mae: 1.8753 - val_loss: 1.9115 - val_mae: 1.9115 - learning_rate: 1.0000e-03\n",
      "Epoch 7/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.8157 - mae: 1.8157 - val_loss: 1.8621 - val_mae: 1.8621 - learning_rate: 1.0000e-03\n",
      "Epoch 8/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7971 - mae: 1.7971 - val_loss: 1.8638 - val_mae: 1.8638 - learning_rate: 1.0000e-03\n",
      "Epoch 9/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7703 - mae: 1.7703 - val_loss: 1.8157 - val_mae: 1.8157 - learning_rate: 1.0000e-03\n",
      "Epoch 10/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7604 - mae: 1.7604 - val_loss: 1.7913 - val_mae: 1.7913 - learning_rate: 1.0000e-03\n",
      "Epoch 11/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7288 - mae: 1.7288 - val_loss: 1.8315 - val_mae: 1.8315 - learning_rate: 1.0000e-03\n",
      "Epoch 12/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7875 - mae: 1.7875 - val_loss: 1.7621 - val_mae: 1.7621 - learning_rate: 1.0000e-03\n",
      "Epoch 13/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.7064 - mae: 1.7064 - val_loss: 1.7472 - val_mae: 1.7472 - learning_rate: 1.0000e-03\n",
      "Epoch 14/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.6972 - mae: 1.6972 - val_loss: 1.7352 - val_mae: 1.7352 - learning_rate: 1.0000e-03\n",
      "Epoch 15/15\n",
      "86/86 - 2s - 18ms/step - loss: 1.6667 - mae: 1.6667 - val_loss: 1.7190 - val_mae: 1.7190 - learning_rate: 1.0000e-03\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "csv_path = 'fastf1_lap_dataset.csv'  # adjust path\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "train_df, mapping = load_and_prepare(csv_path)\n",
    "model = LSTMLapTimeModel()\n",
    "model.fit_from_csv(csv_path, epochs=epochs, batch_size=batch_size)\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc63a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save trained model\n",
    "save_dir = Path('f1_lstm_model')\n",
    "model.save(save_dir)\n",
    "print(f'Saved model to {save_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model\n",
    "load_dir = Path('f1_lstm_model')\n",
    "model = LSTMLapTimeModel()\n",
    "model.load(load_dir)\n",
    "print(f'Loaded model from {load_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e975069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pit loss used: 17.195000000000007\n",
      "Final classification:\n",
      "1: COL (Team)  total_time=2838.09  status=Finished\n",
      "2: BEA (Team)  total_time=2999.22  status=Finished\n",
      "3: ERI (Team)  total_time=3015.90  status=Finished\n",
      "4: GAS (Team)  total_time=3041.81  status=Finished\n",
      "5: DEV (Team)  total_time=3061.39  status=Finished\n",
      "6: BOR (Team)  total_time=3081.05  status=Finished\n",
      "7: ALO (Team)  total_time=3092.47  status=Finished\n",
      "8: GIO (Team)  total_time=3108.94  status=Finished\n",
      "9: BOT (Team)  total_time=3231.57  status=Finished\n",
      "10: ALB (Team)  total_time=3290.88  status=Finished\n",
      "First 3 laps timeline:\n",
      "{\n",
      "  \"lap\": 1,\n",
      "  \"order\": [\n",
      "    \"COL\",\n",
      "    \"ERI\",\n",
      "    \"BEA\",\n",
      "    \"DEV\",\n",
      "    \"GAS\",\n",
      "    \"BOR\",\n",
      "    \"GIO\",\n",
      "    \"ALO\",\n",
      "    \"BOT\",\n",
      "    \"ALB\"\n",
      "  ],\n",
      "  \"lap_times\": {\n",
      "    \"ALB\": 36.16753005981445,\n",
      "    \"ALO\": 33.12236404418945,\n",
      "    \"BEA\": 31.29922866821289,\n",
      "    \"BOR\": 32.304039001464844,\n",
      "    \"BOT\": 35.521728515625,\n",
      "    \"COL\": 28.846202850341797,\n",
      "    \"DEV\": 31.798025131225586,\n",
      "    \"ERI\": 30.989051818847656,\n",
      "    \"GAS\": 32.10897445678711,\n",
      "    \"GIO\": 32.62831115722656\n",
      "  },\n",
      "  \"is_sc\": false\n",
      "}\n",
      "{\n",
      "  \"lap\": 2,\n",
      "  \"order\": [\n",
      "    \"COL\",\n",
      "    \"ERI\",\n",
      "    \"BEA\",\n",
      "    \"DEV\",\n",
      "    \"GAS\",\n",
      "    \"BOR\",\n",
      "    \"GIO\",\n",
      "    \"ALO\",\n",
      "    \"BOT\",\n",
      "    \"ALB\"\n",
      "  ],\n",
      "  \"lap_times\": {\n",
      "    \"COL\": 28.749319076538086,\n",
      "    \"ERI\": 31.39990997314453,\n",
      "    \"BEA\": 31.497814178466797,\n",
      "    \"DEV\": 32.28477096557617,\n",
      "    \"GAS\": 32.43661880493164,\n",
      "    \"BOR\": 32.72930145263672,\n",
      "    \"GIO\": 33.20826721191406,\n",
      "    \"ALO\": 33.525299072265625,\n",
      "    \"BOT\": 36.16478729248047,\n",
      "    \"ALB\": 36.99139404296875\n",
      "  },\n",
      "  \"is_sc\": false\n",
      "}\n",
      "{\n",
      "  \"lap\": 3,\n",
      "  \"order\": [\n",
      "    \"COL\",\n",
      "    \"ERI\",\n",
      "    \"BEA\",\n",
      "    \"DEV\",\n",
      "    \"GAS\",\n",
      "    \"BOR\",\n",
      "    \"GIO\",\n",
      "    \"ALO\",\n",
      "    \"BOT\",\n",
      "    \"ALB\"\n",
      "  ],\n",
      "  \"lap_times\": {\n",
      "    \"COL\": 29.512287139892578,\n",
      "    \"ERI\": 32.43390655517578,\n",
      "    \"BEA\": 32.4378547668457,\n",
      "    \"DEV\": 33.4837646484375,\n",
      "    \"GAS\": 33.381622314453125,\n",
      "    \"BOR\": 33.835025787353516,\n",
      "    \"GIO\": 34.25957107543945,\n",
      "    \"ALO\": 34.614593505859375,\n",
      "    \"BOT\": 37.23966598510742,\n",
      "    \"ALB\": 38.14982223510742\n",
      "  },\n",
      "  \"is_sc\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simulate a race using demo config\n",
    "cfg = demo_config_from_dataset(train_df if 'train_df' in globals() else load_and_prepare(csv_path)[0], mapping if 'mapping' in globals() else load_and_prepare(csv_path)[1])\n",
    "sim = LSTMSimulator(model)\n",
    "result = sim.simulate(cfg)\n",
    "print('Pit loss used:', result.get('pit_loss_used'))\n",
    "print('Final classification:')\n",
    "for row in result['classification']:\n",
    "    pos = row['pos'] if row['pos'] is not None else 'DNF'\n",
    "    print(f\"{pos}: {row['driver']} ({row['team']})  total_time={row['total_time']:.2f}  status={row['status']}\")\n",
    "print('First 3 laps timeline:')\n",
    "for item in result['timeline'][:3]:\n",
    "    print(json.dumps(item, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
