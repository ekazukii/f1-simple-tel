{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bd64b1",
   "metadata": {},
   "source": [
    "\n",
    "# Lap Context Transformer\n",
    "\n",
    "Train a transformer that ingests every lap of a race up to lap `t` and predicts the next lap (`t+1`) lap time and position for all drivers. Each batch may contain races of different lengths; we pad shorter contexts and mask padded tokens during attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c9a6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44682) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ekazuki/Library/Python/3.14/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ekazuki/Library/Python/3.14/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44685) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn tqdm\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef7881",
   "metadata": {},
   "source": [
    "\n",
    "## Imports & configuration\n",
    "Define the training configuration, seed everything, and set up helper functions for statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b71fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "tensor([1.], device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113606250>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=DEVICE)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "def ensure_pos_std(series: pd.Series) -> float:\n",
    "    std = float(series.std())\n",
    "    return std if std > 1e-6 else 1.0\n",
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    dataset_path: Path = Path('fastf1_lap_dataset.csv')\n",
    "    max_drivers: int = 20\n",
    "    min_laps_per_session: int = 5\n",
    "    train_years: Tuple[int, ...] = (2018, 2019, 2020, 2021)\n",
    "    val_years: Tuple[int, ...] = (2023,)\n",
    "    test_years: Tuple[int, ...] = (2024, 2025)\n",
    "    batch_size: int = 2\n",
    "    num_epochs: int = 1\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    max_train_steps_per_epoch: Optional[int] = None\n",
    "    max_val_steps: Optional[int] = None\n",
    "    seed: int = 42\n",
    "    debug_sessions: Optional[int] = None\n",
    "CONFIG = TrainerConfig()\n",
    "np.random.seed(CONFIG.seed)\n",
    "torch.manual_seed(CONFIG.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863b89b",
   "metadata": {},
   "source": [
    "\n",
    "## Load and preprocess the lap dataset\n",
    "Clean missing values, fill lagged lap times, and derive helper columns for gaps, tyre age, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0542b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_lap_dataframe(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required = {'session_key', 'driver_id', 'lap_number'}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing columns: {missing}')\n",
    "    df = df.dropna(subset=list(required)).copy()\n",
    "    df['lap_number'] = df['lap_number'].astype(int)\n",
    "    df = df.sort_values(['session_key', 'driver_id', 'lap_number'])\n",
    "\n",
    "    # Fill various gaps\n",
    "    df['gap_to_leader_s'] = df['gap_to_leader_s'].fillna(0)\n",
    "    df['gap_to_ahead_s'] = df['gap_to_ahead_s'].fillna(0)\n",
    "    # Avoid using lap_number as a proxy for position; carry last known or leave NaN\n",
    "    df['current_position'] = df['current_position'].fillna(method='ffill')\n",
    "    df['current_position'] = df['current_position'].fillna(method='bfill')\n",
    "    df['grid_position'] = df.groupby(['session_key', 'driver_id'])['grid_position'].transform(lambda s: s.fillna(s.iloc[0]))\n",
    "    df['grid_position'] = df['grid_position'].fillna(df['current_position'])\n",
    "    df['grid_position'] = df['grid_position'].fillna(df['lap_number'])\n",
    "    df['laps_on_current_tyre'] = df['laps_on_current_tyre'].fillna(1)\n",
    "    df['lap_time_s'] = df.groupby('session_key')['lap_time_s'].transform(lambda s: s.fillna(s.median()))\n",
    "    df['lap_time_s'] = df['lap_time_s'].fillna(df['lap_time_s'].median())\n",
    "\n",
    "    for col in ['track_temperature', 'air_temperature', 'humidity', 'wind_speed', 'pressure']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    for col in ['drs_enabled', 'safety_car_this_lap', 'virtual_sc_this_lap', 'rainfall', 'has_rain']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(False)\n",
    "    df['tyre_compound'] = df['tyre_compound'].fillna('UNKNOWN')\n",
    "\n",
    "    df['lap_time_prev1'] = df.groupby(['session_key', 'driver_id'])['lap_time_s'].shift(1)\n",
    "    df['lap_time_prev2'] = df.groupby(['session_key', 'driver_id'])['lap_time_s'].shift(2)\n",
    "    df['lap_time_prev1'] = df['lap_time_prev1'].fillna(df['lap_time_s'])\n",
    "    df['lap_time_prev2'] = df['lap_time_prev2'].fillna(df['lap_time_s'])\n",
    "    df['pit_flag'] = False\n",
    "    for (session_key, driver_id), group in df.groupby(['session_key', 'driver_id']):\n",
    "        order = group.sort_values('lap_number')\n",
    "        tyre_diff = order['laps_on_current_tyre'].diff()\n",
    "        compound_change = order['tyre_compound'].ne(order['tyre_compound'].shift(1))\n",
    "        pits = (tyre_diff < 0) | compound_change.fillna(False)\n",
    "        df.loc[order.index, 'pit_flag'] = pits.fillna(False)\n",
    "    return df\n",
    "\n",
    "raw_df = load_lap_dataframe(CONFIG.dataset_path)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2d859",
   "metadata": {},
   "source": [
    "\n",
    "## Track/weather scalers & vocabularies\n",
    "Compute per-track mean/std for lap times and gaps, global weather scalers, and integer vocabularies for drivers/teams/circuits/compounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3307e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 35)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_track_scalers(df: pd.DataFrame) -> Dict[str, Dict[str, Tuple[float, float]]]:\n",
    "    stats = {}\n",
    "    for circuit_id, group in df.groupby('circuit_id'):\n",
    "        lap_series = group['lap_time_s']\n",
    "        gap_leader = np.log1p(group['gap_to_leader_s'])\n",
    "        gap_ahead = np.log1p(group['gap_to_ahead_s'])\n",
    "        stats[circuit_id] = {\n",
    "            'lap_time_s': (float(lap_series.mean()), ensure_pos_std(lap_series)),\n",
    "            'gap_to_leader_s': (float(gap_leader.mean()), ensure_pos_std(gap_leader)),\n",
    "            'gap_to_ahead_s': (float(gap_ahead.mean()), ensure_pos_std(gap_ahead)),\n",
    "        }\n",
    "    if not stats:\n",
    "        raise ValueError('No circuits found for scalers')\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_weather_scaler(df: pd.DataFrame) -> Dict[str, Tuple[float, float]]:\n",
    "    scalers = {}\n",
    "    for col in ['track_temperature', 'air_temperature', 'humidity', 'wind_speed', 'pressure']:\n",
    "        series = df[col].astype(float)\n",
    "        scalers[col] = (float(series.mean()), ensure_pos_std(series))\n",
    "    return scalers\n",
    "\n",
    "track_scalers = compute_track_scalers(raw_df)\n",
    "weather_scaler = compute_weather_scaler(raw_df)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LapVocabulary:\n",
    "    driver_to_idx: Dict[str, int]\n",
    "    team_to_idx: Dict[str, int]\n",
    "    compound_to_idx: Dict[str, int]\n",
    "    track_to_idx: Dict[str, int]\n",
    "\n",
    "    @property\n",
    "    def num_drivers(self) -> int:\n",
    "        return len(self.driver_to_idx) + 1\n",
    "\n",
    "    @property\n",
    "    def num_teams(self) -> int:\n",
    "        return len(self.team_to_idx) + 1\n",
    "\n",
    "    @property\n",
    "    def num_compounds(self) -> int:\n",
    "        return len(self.compound_to_idx) + 1\n",
    "\n",
    "    @property\n",
    "    def num_tracks(self) -> int:\n",
    "        return len(self.track_to_idx) + 1\n",
    "\n",
    "\n",
    "def build_vocab(df: pd.DataFrame) -> LapVocabulary:\n",
    "    return LapVocabulary(\n",
    "        driver_to_idx={drv: idx + 1 for idx, drv in enumerate(sorted(df['driver_id'].unique()))},\n",
    "        team_to_idx={team: idx + 1 for idx, team in enumerate(sorted(df['team_id'].unique()))},\n",
    "        compound_to_idx={comp: idx + 1 for idx, comp in enumerate(sorted(df['tyre_compound'].unique()))},\n",
    "        track_to_idx={trk: idx + 1 for idx, trk in enumerate(sorted(df['circuit_id'].unique()))},\n",
    "    )\n",
    "\n",
    "vocab = build_vocab(raw_df)\n",
    "len(vocab.driver_to_idx), len(vocab.track_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179b945",
   "metadata": {},
   "source": [
    "\n",
    "## Session tensor builder\n",
    "Convert each race (session) into dense tensors: `[laps, max_drivers, dynamics]`, global lap features, categorical tokens, and normalized targets. Only races with at least `min_laps_per_session` laps are kept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0a9fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sessions: 100%|██████████| 168/168 [00:04<00:00, 34.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorized sessions: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SessionTensor:\n",
    "    session_key: str\n",
    "    year: int\n",
    "    track_token: int\n",
    "    dynamic_numeric: np.ndarray\n",
    "    global_numeric: np.ndarray\n",
    "    rank_tokens: np.ndarray\n",
    "    compound_tokens: np.ndarray\n",
    "    alive_mask: np.ndarray\n",
    "    lap_time_norm: np.ndarray\n",
    "    position_norm: np.ndarray\n",
    "    driver_tokens: np.ndarray\n",
    "    team_tokens: np.ndarray\n",
    "    static_numeric: np.ndarray\n",
    "class SessionTensorBuilder:\n",
    "    def __init__(self, cfg: TrainerConfig, vocab: LapVocabulary, track_scalers, weather_scaler):\n",
    "        self.cfg = cfg\n",
    "        self.vocab = vocab\n",
    "        self.track_scalers = track_scalers\n",
    "        self.weather_scaler = weather_scaler\n",
    "    def _zscore(self, value: float, mean: float, std: float) -> float:\n",
    "        if pd.isna(value):\n",
    "            return 0.0\n",
    "        return float((value - mean) / (std if std > 1e-6 else 1.0))\n",
    "    def build(self, df: pd.DataFrame) -> List[SessionTensor]:\n",
    "        sessions = []\n",
    "        for idx, (session_key, sdf) in enumerate(tqdm(df.groupby('session_key', sort=False), desc='Sessions')):\n",
    "            if CONFIG.debug_sessions and idx >= CONFIG.debug_sessions:\n",
    "                break\n",
    "            sdf = sdf.sort_values(['lap_number', 'driver_id']).copy()\n",
    "            max_lap = int(sdf['lap_number'].max())\n",
    "            if max_lap < CONFIG.min_laps_per_session:\n",
    "                continue\n",
    "            drivers = sorted(sdf['driver_id'].unique().tolist())[: CONFIG.max_drivers]\n",
    "            driver_slots = {drv: slot for slot, drv in enumerate(drivers)}\n",
    "            slots = CONFIG.max_drivers\n",
    "            dyn_dim = 12\n",
    "            dynamic = np.zeros((max_lap, slots, dyn_dim), dtype=np.float32)\n",
    "            rank_tokens = np.zeros((max_lap, slots), dtype=np.int64)\n",
    "            compound_tokens = np.zeros((max_lap, slots), dtype=np.int64)\n",
    "            alive = np.zeros((max_lap, slots), dtype=np.float32)\n",
    "            lap_time_norm = np.zeros((max_lap, slots), dtype=np.float32)\n",
    "            global_feats = np.zeros((max_lap, 8), dtype=np.float32)\n",
    "            driver_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "            team_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "            static_numeric = np.zeros((slots, 2), dtype=np.float32)\n",
    "            circuit_id = sdf['circuit_id'].iloc[0]\n",
    "            track_stats = self.track_scalers.get(circuit_id, next(iter(self.track_scalers.values())))\n",
    "            track_token = self.vocab.track_to_idx.get(circuit_id, 0)\n",
    "            total_ref = max(max_lap, int(sdf['total_race_laps'].dropna().max() or max_lap))\n",
    "            for driver_id, rows in sdf.groupby('driver_id'):\n",
    "                if driver_id not in driver_slots:\n",
    "                    continue\n",
    "                slot = driver_slots[driver_id]\n",
    "                driver_tokens[slot] = self.vocab.driver_to_idx.get(driver_id, 0)\n",
    "                team_tokens[slot] = self.vocab.team_to_idx.get(rows['team_id'].iloc[0], 0)\n",
    "                static_numeric[slot, 0] = float(rows['grid_position'].iloc[0] / CONFIG.max_drivers)\n",
    "                static_numeric[slot, 1] = float(rows['year'].iloc[0] - 2018) / 10.0\n",
    "                for _, row in rows.iterrows():\n",
    "                    lap_idx = int(row['lap_number']) - 1\n",
    "                    pos_norm = (float(row['current_position']) - 1) / max(1, CONFIG.max_drivers - 1)\n",
    "                    dynamic[lap_idx, slot, 0] = pos_norm\n",
    "                    dynamic[lap_idx, slot, 1] = float(row['grid_position']) / CONFIG.max_drivers\n",
    "                    lap_mean, lap_std = track_stats['lap_time_s']\n",
    "                    lap_norm = self._zscore(row['lap_time_s'], lap_mean, lap_std)\n",
    "                    dynamic[lap_idx, slot, 2] = lap_norm\n",
    "                    dynamic[lap_idx, slot, 3] = self._zscore(row['lap_time_prev1'], lap_mean, lap_std)\n",
    "                    dynamic[lap_idx, slot, 4] = self._zscore(row['lap_time_prev2'], lap_mean, lap_std)\n",
    "                    gap_mean, gap_std = track_stats['gap_to_leader_s']\n",
    "                    ahead_mean, ahead_std = track_stats['gap_to_ahead_s']\n",
    "                    dynamic[lap_idx, slot, 5] = self._zscore(np.log1p(row['gap_to_leader_s']), gap_mean, gap_std)\n",
    "                    dynamic[lap_idx, slot, 6] = self._zscore(np.log1p(row['gap_to_ahead_s']), ahead_mean, ahead_std)\n",
    "                    dynamic[lap_idx, slot, 7] = float(row['laps_on_current_tyre']) / 50.0\n",
    "                    dynamic[lap_idx, slot, 8] = float(row['pit_flag'])\n",
    "                    dynamic[lap_idx, slot, 9] = float(row['drs_enabled'])\n",
    "                    dynamic[lap_idx, slot, 10] = float(row['safety_car_this_lap'])\n",
    "                    dynamic[lap_idx, slot, 11] = float(row['virtual_sc_this_lap'])\n",
    "                    compound_tokens[lap_idx, slot] = self.vocab.compound_to_idx.get(row['tyre_compound'], 0)\n",
    "                    rank_tokens[lap_idx, slot] = int(row['current_position']) - 1\n",
    "                    lap_time_norm[lap_idx, slot] = lap_norm\n",
    "                    alive[lap_idx, slot] = 1.0\n",
    "            for lap_idx in range(max_lap):\n",
    "                lap_no = lap_idx + 1\n",
    "                frac = lap_no / total_ref\n",
    "                remaining = (total_ref - lap_no) / total_ref\n",
    "                global_feats[lap_idx, 0] = frac\n",
    "                global_feats[lap_idx, 1] = remaining\n",
    "                row = sdf[sdf['lap_number'] == lap_no].iloc[0]\n",
    "                for g_idx, col in enumerate(['track_temperature', 'air_temperature', 'humidity', 'wind_speed'], start=2):\n",
    "                    mean, std = self.weather_scaler[col]\n",
    "                    global_feats[lap_idx, g_idx] = self._zscore(row[col], mean, std)\n",
    "                global_feats[lap_idx, 6] = float(row['has_rain'])\n",
    "                p_mean, p_std = self.weather_scaler['pressure']\n",
    "                global_feats[lap_idx, 7] = self._zscore(row['pressure'], p_mean, p_std)\n",
    "            position_norm = rank_tokens.astype(np.float32)\n",
    "            if CONFIG.max_drivers > 1:\n",
    "                position_norm /= (CONFIG.max_drivers - 1)\n",
    "            sessions.append(SessionTensor(\n",
    "                session_key=session_key,\n",
    "                year=int(sdf['year'].iloc[0]),\n",
    "                track_token=track_token,\n",
    "                dynamic_numeric=dynamic,\n",
    "                global_numeric=global_feats,\n",
    "                rank_tokens=rank_tokens,\n",
    "                compound_tokens=compound_tokens,\n",
    "                alive_mask=alive,\n",
    "                lap_time_norm=lap_time_norm,\n",
    "                position_norm=position_norm,\n",
    "                driver_tokens=driver_tokens,\n",
    "                team_tokens=team_tokens,\n",
    "                static_numeric=static_numeric,\n",
    "            ))\n",
    "        return sessions\n",
    "builder = SessionTensorBuilder(CONFIG, vocab, track_scalers, weather_scaler)\n",
    "session_tensors = builder.build(raw_df)\n",
    "print(f\"Tensorized sessions: {len(session_tensors)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3283e",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset: full context, next-lap target\n",
    "Each sample contains all laps up to `t` and predicts lap `t+1`. We pad contexts per batch and build masks automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62519c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4837 | Val: 1412\n"
     ]
    }
   ],
   "source": [
    "class LapContextDataset(Dataset):\n",
    "    def __init__(self, sessions: Sequence[SessionTensor], cfg: TrainerConfig, years: Tuple[int, ...]):\n",
    "        self.sessions = [s for s in sessions if s.year in years]\n",
    "        self.cfg = cfg\n",
    "        self.indices: List[Tuple[int, int]] = []\n",
    "        for sess_idx, sess in enumerate(self.sessions):\n",
    "            T = sess.dynamic_numeric.shape[0]\n",
    "            for target_idx in range(1, T):\n",
    "                self.indices.append((sess_idx, target_idx))\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        sess_idx, target_idx = self.indices[idx]\n",
    "        sess = self.sessions[sess_idx]\n",
    "        ctx_slice = slice(0, target_idx)\n",
    "        return {\n",
    "            'dynamic': torch.from_numpy(sess.dynamic_numeric[ctx_slice]).float(),\n",
    "            'global': torch.from_numpy(sess.global_numeric[ctx_slice]).float(),\n",
    "            'compound_tokens': torch.from_numpy(sess.compound_tokens[ctx_slice]).long(),\n",
    "            'rank_tokens': torch.from_numpy(sess.rank_tokens[ctx_slice]).long(),\n",
    "            'alive_mask': torch.from_numpy(sess.alive_mask[ctx_slice]).float(),\n",
    "            'context_length': torch.tensor(target_idx, dtype=torch.long),\n",
    "            'driver_tokens': torch.from_numpy(sess.driver_tokens).long(),\n",
    "            'team_tokens': torch.from_numpy(sess.team_tokens).long(),\n",
    "            'static_numeric': torch.from_numpy(sess.static_numeric).float(),\n",
    "            'track_token': torch.tensor(sess.track_token).long(),\n",
    "            'target_lap_time': torch.from_numpy(sess.lap_time_norm[target_idx]).float(),\n",
    "            'target_position': torch.from_numpy(sess.position_norm[target_idx]).float(),\n",
    "            'target_alive': torch.from_numpy(sess.alive_mask[target_idx]).float(),\n",
    "        }\n",
    "def pad_tensor(seq: torch.Tensor, target_len: int) -> torch.Tensor:\n",
    "    if seq.shape[0] == target_len:\n",
    "        return seq\n",
    "    pad_shape = (target_len - seq.shape[0],) + tuple(seq.shape[1:])\n",
    "    pad_tensor = torch.zeros(pad_shape, dtype=seq.dtype)\n",
    "    return torch.cat([seq, pad_tensor], dim=0)\n",
    "def collate_context(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    max_len = max(int(item['context_length']) for item in batch)\n",
    "    out: Dict[str, torch.Tensor] = {}\n",
    "    for key in ['dynamic', 'global', 'compound_tokens', 'rank_tokens', 'alive_mask']:\n",
    "        out[key] = torch.stack([pad_tensor(item[key], max_len) for item in batch], dim=0)\n",
    "    out['context_length'] = torch.stack([item['context_length'] for item in batch], dim=0)\n",
    "    out['driver_tokens'] = torch.stack([item['driver_tokens'] for item in batch], dim=0)\n",
    "    out['team_tokens'] = torch.stack([item['team_tokens'] for item in batch], dim=0)\n",
    "    out['static_numeric'] = torch.stack([item['static_numeric'] for item in batch], dim=0)\n",
    "    out['track_token'] = torch.stack([item['track_token'] for item in batch], dim=0)\n",
    "    out['target_lap_time'] = torch.stack([item['target_lap_time'] for item in batch], dim=0)\n",
    "    out['target_position'] = torch.stack([item['target_position'] for item in batch], dim=0)\n",
    "    out['target_alive'] = torch.stack([item['target_alive'] for item in batch], dim=0)\n",
    "    return out\n",
    "train_dataset = LapContextDataset(session_tensors, CONFIG, CONFIG.train_years)\n",
    "val_dataset = LapContextDataset(session_tensors, CONFIG, CONFIG.val_years)\n",
    "print(f\"Train samples: {len(train_dataset)} | Val: {len(val_dataset)}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True, collate_fn=collate_context, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG.batch_size, shuffle=False, collate_fn=collate_context, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35739b",
   "metadata": {},
   "source": [
    "\n",
    "## Lap context transformer\n",
    "Driver tokens are concatenated with lap/slot embeddings, dynamic scalars, and global features, then passed through a transformer encoder. We gather the last-lap tokens to predict the next lap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6596ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LapContextTransformer(nn.Module):\n",
    "    def __init__(self, cfg: TrainerConfig, vocab: LapVocabulary, dyn_dim: int, global_dim: int, static_dim: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.driver_emb = nn.Embedding(vocab.num_drivers + 1, 32, padding_idx=0)\n",
    "        self.team_emb = nn.Embedding(vocab.num_teams + 1, 16, padding_idx=0)\n",
    "        self.compound_emb = nn.Embedding(vocab.num_compounds + 1, 8, padding_idx=0)\n",
    "        self.rank_emb = nn.Embedding(cfg.max_drivers + 1, 8, padding_idx=0)\n",
    "        self.slot_emb = nn.Embedding(cfg.max_drivers, 8)\n",
    "        self.track_emb = nn.Embedding(vocab.num_tracks + 1, 16, padding_idx=0)\n",
    "        self.lap_pos_emb = nn.Embedding(256, 32)\n",
    "        self.static_proj = nn.Linear(static_dim + 32 + 16, 64)\n",
    "        self.global_proj = nn.Linear(global_dim + 16 + 32, 64)\n",
    "        self.token_proj = nn.Linear(dyn_dim + 8 + 8 + 8 + 64 + 64, 256)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=1024, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.time_head = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "        self.position_head = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        B, T_ctx, N, _ = batch['dynamic'].shape\n",
    "        dyn = batch['dynamic'].to(DEVICE)\n",
    "        if DEVICE.type == \"mps\" and dyn.device.type != \"mps\":\n",
    "            raise RuntimeError(\"Expected MPS tensors; got CPU (fallback). Disable fallback or reduce batch size.\")\n",
    "        rank_tokens = batch['rank_tokens'].to(DEVICE)\n",
    "        compound_tokens = batch['compound_tokens'].to(DEVICE)\n",
    "        alive = batch['alive_mask'].to(DEVICE)\n",
    "        global_feats = batch['global'].to(DEVICE)\n",
    "        track_tokens = batch['track_token'].to(DEVICE)\n",
    "        driver_tokens = batch['driver_tokens'].to(DEVICE)\n",
    "        team_tokens = batch['team_tokens'].to(DEVICE)\n",
    "        static_numeric = batch['static_numeric'].to(DEVICE)\n",
    "        context_lengths = batch['context_length'].to(DEVICE)\n",
    "        driver_emb = self.driver_emb(driver_tokens)\n",
    "        team_emb = self.team_emb(team_tokens)\n",
    "        static_feat = torch.cat([static_numeric, driver_emb, team_emb], dim=-1)\n",
    "        static_feat = self.static_proj(static_feat).unsqueeze(1).expand(-1, T_ctx, -1, -1)\n",
    "        lap_positions = torch.arange(T_ctx, device=DEVICE).view(1, T_ctx).expand(B, T_ctx)\n",
    "        lap_emb = self.lap_pos_emb(torch.clamp(lap_positions, max=self.lap_pos_emb.num_embeddings - 1))\n",
    "        track_emb = self.track_emb(track_tokens).unsqueeze(1).expand(-1, T_ctx, -1)\n",
    "        global_cat = torch.cat([global_feats, track_emb, lap_emb], dim=-1)\n",
    "        global_feat = self.global_proj(global_cat).unsqueeze(2).expand(-1, -1, N, -1)\n",
    "        slot_idx = torch.arange(N, device=DEVICE).view(1, 1, N).expand(B, T_ctx, N)\n",
    "        slot_emb = self.slot_emb(torch.clamp(slot_idx, max=self.cfg.max_drivers - 1))\n",
    "        rank_emb = self.rank_emb(torch.clamp(rank_tokens, max=self.cfg.max_drivers))\n",
    "        compound_emb = self.compound_emb(compound_tokens)\n",
    "        tokens = torch.cat([dyn, rank_emb, compound_emb, slot_emb, static_feat, global_feat], dim=-1)\n",
    "        tokens = self.token_proj(tokens)\n",
    "        tokens = tokens.view(B, T_ctx * N, -1)\n",
    "        key_padding = ~(alive.view(B, T_ctx * N).bool())\n",
    "        encoded = self.encoder(tokens, src_key_padding_mask=key_padding)\n",
    "        last_idx = torch.clamp(context_lengths - 1, min=0)\n",
    "        base = last_idx * N\n",
    "        gather = base.unsqueeze(1) + torch.arange(N, device=DEVICE)\n",
    "        gather = torch.clamp(gather, max=T_ctx * N - 1)\n",
    "        encoded_last = torch.gather(encoded, 1, gather.unsqueeze(-1).expand(-1, -1, encoded.shape[-1]))\n",
    "        pred_time = self.time_head(encoded_last).squeeze(-1)\n",
    "        pred_pos = self.position_head(encoded_last).squeeze(-1)\n",
    "        return {'lap_time': pred_time, 'position': pred_pos}\n",
    "model = LapContextTransformer(\n",
    "    CONFIG,\n",
    "    vocab,\n",
    "    dyn_dim=session_tensors[0].dynamic_numeric.shape[-1],\n",
    "    global_dim=session_tensors[0].global_numeric.shape[-1],\n",
    "    static_dim=session_tensors[0].static_numeric.shape[-1],\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a53f1b",
   "metadata": {},
   "source": [
    "\n",
    "## Training & evaluation loops\n",
    "Use SmoothL1 loss on lap time and position, mask retired/padded drivers, and average per batch. The evaluation computes the same metrics without gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4ef02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.SmoothL1Loss(reduction='none')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "\n",
    "def step(model, batch, train=True):\n",
    "    preds = model(batch)\n",
    "    alive = batch['target_alive'].to(DEVICE)\n",
    "    time_tgt = batch['target_lap_time'].to(DEVICE)\n",
    "    pos_tgt = batch['target_position'].to(DEVICE)\n",
    "\n",
    "    time_loss = loss_fn(preds['lap_time'], time_tgt)\n",
    "    pos_loss = loss_fn(preds['position'], pos_tgt)\n",
    "    denom = max(alive.sum().item(), 1.0)\n",
    "    time_loss = (time_loss * alive).sum() / denom\n",
    "    pos_loss = (pos_loss * alive).sum() / denom\n",
    "    total = time_loss + pos_loss\n",
    "\n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "        total.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    return {'time_loss': time_loss.item(), 'position_loss': pos_loss.item(), 'total': total.item()}\n",
    "\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    metrics = []\n",
    "    print(f\"Starting {'train' if train else 'val'} epoch with {len(loader)} batches\")\n",
    "    iterator = tqdm(loader, desc='train' if train else 'val', leave=True, mininterval=0.2, dynamic_ncols=True)\n",
    "    steps = 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for batch in iterator:\n",
    "            stats = step(model, batch, train=train)\n",
    "            iterator.set_postfix({k: f\"{v:.3f}\" for k, v in stats.items()})\n",
    "            metrics.append(stats)\n",
    "            steps += 1\n",
    "            limit = CONFIG.max_train_steps_per_epoch if train else CONFIG.max_val_steps\n",
    "            if limit and steps >= limit:\n",
    "                break\n",
    "    if not metrics:\n",
    "        return {}\n",
    "    return {k: float(np.mean([m[k] for m in metrics])) for k in metrics[0]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e48bf",
   "metadata": {},
   "source": [
    "\n",
    "## Train the model\n",
    "Adjust `num_epochs`, `max_train_steps_per_epoch`, or `max_val_steps` in CONFIG if you want shorter runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d455d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train epoch with 2419 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  28%|██▊       | 673/2419 [03:42<1:29:33,  3.08s/it, time_loss=0.017, position_loss=0.040, total=0.057]"
     ]
    }
   ],
   "source": [
    "\n",
    "train_history = []\n",
    "val_history = []\n",
    "for epoch in range(1, CONFIG.num_epochs + 1):\n",
    "    train_metrics = run_epoch(train_loader, train=True)\n",
    "    val_metrics = run_epoch(val_loader, train=False)\n",
    "    train_history.append(train_metrics)\n",
    "    val_history.append(val_metrics)\n",
    "    print(f\"Epoch {epoch}: train={train_metrics} | val={val_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4620bc",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate (optional)\n",
    "Compute validation MAE on the normalized lap times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bb964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation lap-time MAE (normalized units): nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "mae_vals = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        stats = step(model, batch, train=False)\n",
    "        mae_vals.append(stats['time_loss'])\n",
    "        if CONFIG.max_val_steps and batch_idx + 1 >= CONFIG.max_val_steps:\n",
    "            break\n",
    "val_mae = float(np.mean(mae_vals)) if mae_vals else float('nan')\n",
    "print(f\"Validation lap-time MAE (normalized units): {val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ea9c3",
   "metadata": {},
   "source": [
    "\n",
    "## Save checkpoint\n",
    "Persist the trained weights along with config and vocab metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f98eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': CONFIG.__dict__,\n",
    "    'vocab': {\n",
    "        'driver_to_idx': vocab.driver_to_idx,\n",
    "        'team_to_idx': vocab.team_to_idx,\n",
    "        'compound_to_idx': vocab.compound_to_idx,\n",
    "        'track_to_idx': vocab.track_to_idx,\n",
    "    },\n",
    "}\n",
    "ckpt_path = Path('models/lap_context_transformer.ckpt')\n",
    "torch.save(checkpoint, ckpt_path)\n",
    "print(f'Saved checkpoint to {ckpt_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4aa00999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lap driver_id  driver_slot  pred_position  pred_lap_time_s\n",
      "0     1       HAM            1              1       102.686060\n",
      "1     1       VET            2              2       102.686060\n",
      "2     1       BOT            3              3       102.686060\n",
      "3     1       SAI            4              4       102.686060\n",
      "4     1       PER            5              5       102.686060\n",
      "5     1       RIC            6              6       102.686060\n",
      "6     1       RAI            7              7       102.686060\n",
      "7     1       VER            8              8       102.686060\n",
      "8     2       HAM            1              1       101.905184\n",
      "9     2       VET            2              2       102.659774\n",
      "10    2       BOT            3              3       101.772095\n",
      "11    2       SAI            4              4       101.824601\n",
      "12    2       PER            5              5       101.644281\n",
      "13    2       RIC            6              6       101.654776\n",
      "14    2       RAI            7              7       101.321278\n",
      "15    2       VER            8              8       101.923621\n",
      "16    3       HAM            1              3       101.727999\n",
      "17    3       VET            2              4       102.004182\n",
      "18    3       BOT            3              5       101.890964\n",
      "19    3       SAI            4              6       101.992223\n",
      "Lap times (s):\n",
      "driver_id      BOT      HAM      PER      RAI      RIC      SAI      VER  \\\n",
      "lap                                                                        \n",
      "1          102.686  102.686  102.686  102.686  102.686  102.686  102.686   \n",
      "2          101.772  101.905  101.644  101.321  101.655  101.825  101.924   \n",
      "3          101.891  101.728  102.054  102.271  101.362  101.992  101.951   \n",
      "4          101.803  101.896  101.168  101.580  101.573  101.620  102.160   \n",
      "5          101.255  102.100  101.094  101.789  101.917  102.227  101.395   \n",
      "6          101.650  101.839  101.739  101.535  103.002  102.199  101.734   \n",
      "7          102.204  100.712  102.126  102.548  101.640  101.529  101.753   \n",
      "8          101.608  102.566  101.452  101.426  101.732  101.309  101.575   \n",
      "9          102.064  101.963  101.900  101.721  101.622  101.653  101.910   \n",
      "10         101.688  102.185  102.097  101.673  102.177  101.974  101.211   \n",
      "11         101.911  101.964  101.325  102.021  101.623  102.072  101.987   \n",
      "12         101.315  101.333  101.330  101.621  102.223  101.720  101.967   \n",
      "\n",
      "driver_id      VET  \n",
      "lap                 \n",
      "1          102.686  \n",
      "2          102.660  \n",
      "3          102.004  \n",
      "4          101.951  \n",
      "5          101.732  \n",
      "6          101.451  \n",
      "7          101.769  \n",
      "8          102.353  \n",
      "9          100.476  \n",
      "10         101.233  \n",
      "11         101.834  \n",
      "12         102.673  \n",
      "Positions (1=leader):\n",
      "driver_id  BOT  HAM  PER  RAI  RIC  SAI  VER  VET\n",
      "lap                                              \n",
      "1            3    1    5    7    6    4    8    2\n",
      "2            3    1    5    7    6    4    8    2\n",
      "3            5    3    1    8    7    6    2    4\n",
      "4            6    4    7    8    2    1    3    5\n",
      "5            4    1    5    7    6    2    8    3\n",
      "6            5    3    6    7    2    1    8    4\n",
      "7            3    1    5    7    6    4    8    2\n",
      "8            4    1    6    7    2    5    8    3\n",
      "9            4    2    5    7    6    1    8    3\n",
      "10           6    5    3    8    7    2    4    1\n",
      "11           5    1    4    7    6    3    8    2\n",
      "12           3    1    5    7    6    4    8    2\n",
      "Predicted lap-time z-score stats per lap:\n",
      "    lap     min_z     max_z    mean_z\n",
      "0     2 -0.202450 -0.003899 -0.125770\n",
      "1     3 -0.196364 -0.061562 -0.115593\n",
      "2     4 -0.225222 -0.078023 -0.143452\n",
      "3     5 -0.236190 -0.068070 -0.147986\n",
      "4     6 -0.183226  0.046929 -0.117544\n",
      "5     7 -0.292867 -0.020550 -0.133653\n",
      "6     8 -0.204271 -0.017851 -0.138483\n",
      "7     9 -0.327790 -0.092283 -0.151691\n",
      "8    10 -0.218754 -0.074278 -0.134411\n",
      "9    11 -0.201965 -0.091124 -0.125203\n",
      "10   12 -0.203443 -0.001955 -0.135480\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Simple lap-by-lap simulation using the trained model and real drivers with light dynamics.\n",
    "def simulate_race(model, track_id=None, total_laps=12, num_drivers=8, drivers=None, teams=None, seed=0,\n",
    "                 safety_car_laps=None, vsc_laps=None, rain_laps=None, drs_enabled_laps=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    model.eval()\n",
    "    sc_set = set(safety_car_laps or [])\n",
    "    vsc_set = set(vsc_laps or [])\n",
    "    rain_set = set(rain_laps or [])\n",
    "    drs_set = set(drs_enabled_laps or [])\n",
    "    track_id = track_id or next(iter(track_scalers.keys()))\n",
    "    track_stats = track_scalers[track_id]\n",
    "    track_token = vocab.track_to_idx.get(track_id, 0)\n",
    "    slots = CONFIG.max_drivers\n",
    "    num_drivers = min(num_drivers, slots)\n",
    "\n",
    "    if drivers is None:\n",
    "        top_drivers = (\n",
    "            raw_df[raw_df['year'].isin(CONFIG.train_years)]\n",
    "            .groupby('driver_id')\n",
    "            .size()\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "        drivers = top_drivers.head(num_drivers).index.tolist()\n",
    "    else:\n",
    "        drivers = drivers[:num_drivers]\n",
    "\n",
    "    if teams is None:\n",
    "        first_team = (\n",
    "            raw_df.dropna(subset=['team_id'])\n",
    "            .drop_duplicates('driver_id')\n",
    "            .set_index('driver_id')['team_id']\n",
    "        )\n",
    "        teams = [first_team.get(drv, \"TEAM_SIM\") for drv in drivers]\n",
    "    else:\n",
    "        teams = teams[:num_drivers]\n",
    "\n",
    "    dyn_dim = session_tensors[0].dynamic_numeric.shape[-1]\n",
    "    global_dim = session_tensors[0].global_numeric.shape[-1]\n",
    "    static_dim = session_tensors[0].static_numeric.shape[-1]\n",
    "\n",
    "    dynamic = np.zeros((total_laps, slots, dyn_dim), dtype=np.float32)\n",
    "    rank_tokens = np.zeros((total_laps, slots), dtype=np.int64)\n",
    "    compound_tokens = np.zeros((total_laps, slots), dtype=np.int64)\n",
    "    alive = np.zeros((total_laps, slots), dtype=np.float32)\n",
    "    global_feats = np.zeros((total_laps, global_dim), dtype=np.float32)\n",
    "    driver_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "    team_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "    static_numeric = np.zeros((slots, static_dim), dtype=np.float32)\n",
    "    laps_on_tyre = np.ones((slots,), dtype=np.float32)\n",
    "    gap_to_leader = np.zeros((slots,), dtype=np.float32)\n",
    "\n",
    "    compound_idx = vocab.compound_to_idx.get('UNKNOWN', 0)\n",
    "    compound_tokens[:, :num_drivers] = compound_idx\n",
    "    alive[:, :num_drivers] = 1.0\n",
    "\n",
    "    for slot in range(num_drivers):\n",
    "        driver_tokens[slot] = vocab.driver_to_idx.get(drivers[slot], 0)\n",
    "        team_tokens[slot] = vocab.team_to_idx.get(teams[slot], 0)\n",
    "        static_numeric[slot, 0] = float(slot + 1) / CONFIG.max_drivers\n",
    "        static_numeric[slot, 1] = (CONFIG.train_years[-1] - 2018) / 10.0\n",
    "\n",
    "    for lap_idx in range(total_laps):\n",
    "        lap_no = lap_idx + 1\n",
    "        frac = lap_no / total_laps\n",
    "        remaining = (total_laps - lap_no) / total_laps\n",
    "        global_feats[lap_idx, 0] = frac\n",
    "        global_feats[lap_idx, 1] = remaining\n",
    "        # sample weather around scaler mean with some variability (z-score units)\n",
    "        for g_idx, col in enumerate(['track_temperature', 'air_temperature', 'humidity', 'wind_speed'], start=2):\n",
    "            mean, std = weather_scaler[col]\n",
    "            # draw actual value then z-score\n",
    "            val = rng.normal(mean, std)\n",
    "            global_feats[lap_idx, g_idx] = (val - mean) / (std if std > 1e-6 else 1.0)\n",
    "        # occasional rain/pressure shifts\n",
    "        rain_flag = 1.0 if lap_no in rain_set else float(rng.random() < 0.05)\n",
    "        global_feats[lap_idx, 6] = rain_flag\n",
    "        p_mean, p_std = weather_scaler['pressure']\n",
    "        p_val = rng.normal(p_mean, p_std)\n",
    "        global_feats[lap_idx, 7] = (p_val - p_mean) / (p_std if p_std > 1e-6 else 1.0)\n",
    "\n",
    "    lap_mean, lap_std = track_stats['lap_time_s']\n",
    "    gap_mean, gap_std = track_stats['gap_to_leader_s']\n",
    "    ahead_mean, ahead_std = track_stats['gap_to_ahead_s']\n",
    "\n",
    "    def gap_z(val, mean, std):\n",
    "        return float((val - mean) / (std if std > 1e-6 else 1.0))\n",
    "\n",
    "    # Seed lap 1 with grid order, mean lap time, and small base gaps.\n",
    "    for slot in range(num_drivers):\n",
    "        grid_norm = float(slot + 1) / CONFIG.max_drivers\n",
    "        pos_norm = float(slot) / max(1, CONFIG.max_drivers - 1)\n",
    "        dynamic[0, slot, 0] = pos_norm\n",
    "        dynamic[0, slot, 1] = grid_norm\n",
    "        dynamic[0, slot, 2] = 0.0\n",
    "        dynamic[0, slot, 3] = 0.0\n",
    "        dynamic[0, slot, 4] = 0.0\n",
    "        base_gap = rng.uniform(0.3, 1.2) * slot\n",
    "        gap_to_leader[slot] = base_gap\n",
    "        gap_ahead = base_gap - (gap_to_leader[slot - 1] if slot > 0 else 0.0)\n",
    "        dynamic[0, slot, 5] = gap_z(np.log1p(gap_to_leader[slot]), np.log1p(gap_mean), gap_std)\n",
    "        dynamic[0, slot, 6] = gap_z(np.log1p(max(gap_ahead, 1e-3)), np.log1p(ahead_mean), ahead_std)\n",
    "        dynamic[0, slot, 7] = laps_on_tyre[slot] / 50.0\n",
    "        dynamic[0, slot, 8] = 0.0\n",
    "        dynamic[0, slot, 9] = 1.0 if 1 in drs_set else 0.0\n",
    "        dynamic[0, slot, 10] = 1.0 if 1 in sc_set else 0.0\n",
    "        dynamic[0, slot, 11] = 1.0 if 1 in vsc_set else 0.0\n",
    "        rank_tokens[0, slot] = slot\n",
    "\n",
    "    records = []\n",
    "    for slot in range(num_drivers):\n",
    "        records.append({\n",
    "            'lap': 1,\n",
    "            'driver_id': drivers[slot],\n",
    "            'driver_slot': slot + 1,\n",
    "            'pred_position': slot + 1,\n",
    "            'pred_lap_time_s': lap_mean,\n",
    "        })\n",
    "\n",
    "    debug_log = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lap_idx in range(1, total_laps):\n",
    "            context_len = lap_idx\n",
    "            batch = {\n",
    "                'dynamic': torch.from_numpy(dynamic[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'global': torch.from_numpy(global_feats[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'compound_tokens': torch.from_numpy(compound_tokens[:context_len]).unsqueeze(0).long().to(DEVICE),\n",
    "                'rank_tokens': torch.from_numpy(rank_tokens[:context_len]).unsqueeze(0).long().to(DEVICE),\n",
    "                'alive_mask': torch.from_numpy(alive[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'context_length': torch.tensor([context_len], device=DEVICE),\n",
    "                'driver_tokens': torch.from_numpy(driver_tokens).unsqueeze(0).long().to(DEVICE),\n",
    "                'team_tokens': torch.from_numpy(team_tokens).unsqueeze(0).long().to(DEVICE),\n",
    "                'static_numeric': torch.from_numpy(static_numeric).unsqueeze(0).float().to(DEVICE),\n",
    "                'track_token': torch.tensor([track_token], device=DEVICE).long(),\n",
    "            }\n",
    "\n",
    "            preds = model(batch)\n",
    "            lap_time_norm = preds['lap_time'][0, :num_drivers].cpu().numpy()\n",
    "            # add per-driver pace offsets (derived from embedding index) and small noise\n",
    "            pace_offsets = rng.normal(0.0, 0.05, size=num_drivers)\n",
    "            lap_time_norm = lap_time_norm + pace_offsets\n",
    "            lap_time_norm = lap_time_norm + rng.normal(0.0, 0.02, size=num_drivers)\n",
    "            pos_norm = preds['position'][0, :num_drivers].cpu().numpy()\n",
    "            pos_norm = np.clip(pos_norm, 0.0, 1.0)\n",
    "\n",
    "            debug_log.append({\n",
    "                'lap': lap_idx + 1,\n",
    "                'min_z': float(lap_time_norm.min()),\n",
    "                'max_z': float(lap_time_norm.max()),\n",
    "                'mean_z': float(lap_time_norm.mean()),\n",
    "            })\n",
    "\n",
    "            ranks = np.argsort(pos_norm)\n",
    "            slot_rank = np.zeros(num_drivers, dtype=np.int64)\n",
    "            slot_rank[ranks] = np.arange(num_drivers)\n",
    "            rank_tokens[lap_idx, :num_drivers] = slot_rank\n",
    "\n",
    "            drift = rng.normal(0.0, 0.3, size=num_drivers) + slot_rank * 0.2\n",
    "            gap_to_leader[:num_drivers] += drift.astype(np.float32)\n",
    "            gap_to_leader[:num_drivers] = np.maximum(gap_to_leader[:num_drivers], 0.0)\n",
    "            gap_to_leader[:num_drivers] -= gap_to_leader[:num_drivers].min()\n",
    "            gap_ahead = np.diff(np.concatenate([[0.0], gap_to_leader[:num_drivers]]))\n",
    "\n",
    "            for slot in range(num_drivers):\n",
    "                laps_on_tyre[slot] = min(laps_on_tyre[slot] + 1, 50)\n",
    "                if lap_idx > 0 and (lap_idx % 8 == 0) and slot == rng.integers(0, num_drivers):\n",
    "                    laps_on_tyre[slot] = 1\n",
    "                    dynamic[lap_idx, slot, 8] = 1.0\n",
    "                dynamic[lap_idx, slot, 0] = pos_norm[slot]\n",
    "                dynamic[lap_idx, slot, 1] = float(slot + 1) / CONFIG.max_drivers\n",
    "                dynamic[lap_idx, slot, 2] = lap_time_norm[slot] + rng.normal(0.0, 0.01)\n",
    "                dynamic[lap_idx, slot, 3] = dynamic[lap_idx - 1, slot, 2]\n",
    "                dynamic[lap_idx, slot, 4] = dynamic[lap_idx - 2, slot, 2] if lap_idx >= 2 else dynamic[lap_idx - 1, slot, 2]\n",
    "                dynamic[lap_idx, slot, 5] = gap_z(np.log1p(gap_to_leader[slot]), np.log1p(gap_mean), gap_std)\n",
    "                gap_ahead_val = max(gap_ahead[slot], 1e-3) if slot < len(gap_ahead) else gap_ahead[-1]\n",
    "                dynamic[lap_idx, slot, 6] = gap_z(np.log1p(gap_ahead_val), np.log1p(ahead_mean), ahead_std)\n",
    "                dynamic[lap_idx, slot, 7] = laps_on_tyre[slot] / 50.0\n",
    "                dynamic[lap_idx, slot, 8] = dynamic[lap_idx, slot, 8] if dynamic[lap_idx, slot, 8] else 0.0\n",
    "                dynamic[lap_idx, slot, 9] = 1.0 if (lap_idx + 1) in drs_set else 0.0\n",
    "                dynamic[lap_idx, slot, 10] = 1.0 if (lap_idx + 1) in sc_set else 0.0\n",
    "                dynamic[lap_idx, slot, 11] = 1.0 if (lap_idx + 1) in vsc_set else 0.0\n",
    "            lap_times_s = lap_time_norm * lap_std + lap_mean\n",
    "            for slot in range(num_drivers):\n",
    "                records.append({\n",
    "                    'lap': lap_idx + 1,\n",
    "                    'driver_id': drivers[slot],\n",
    "                    'driver_slot': slot + 1,\n",
    "                    'pred_position': int(slot_rank[slot] + 1),\n",
    "                    'pred_lap_time_s': float(lap_times_s[slot]),\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    lap_time_table = df.pivot(index='lap', columns='driver_id', values='pred_lap_time_s')\n",
    "    position_table = df.pivot(index='lap', columns='driver_id', values='pred_position')\n",
    "    debug_df = pd.DataFrame(debug_log)\n",
    "    return df, lap_time_table, position_table, debug_df\n",
    "\n",
    "sim_df, lap_time_table, position_table, debug_df = simulate_race(\n",
    "    model,\n",
    "    track_id=list(track_scalers.keys())[0],\n",
    "    total_laps=12,\n",
    "    num_drivers=8,\n",
    ")\n",
    "print(sim_df.head(20))\n",
    "print(\"Lap times (s):\")\n",
    "print(lap_time_table.round(3))\n",
    "print(\"Positions (1=leader):\")\n",
    "print(position_table.astype(int))\n",
    "print(\"Predicted lap-time z-score stats per lap:\")\n",
    "print(debug_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93581ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "ckpt_path = pathlib.Path('models/lap_context_transformer.ckpt')\n",
    "if ckpt_path.exists():\n",
    "    torch.serialization.add_safe_globals([pathlib.PosixPath])\n",
    "    checkpoint = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(f\"Loaded checkpoint from {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5de7b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lap driver_id  driver_slot  pred_position  pred_lap_time_s\n",
      "0     1       VER            1              1        81.429972\n",
      "1     1       PIA            2              2        81.429972\n",
      "2     1       NOR            3              3        81.429972\n",
      "3     1       LEC            4              4        81.429972\n",
      "4     1       RUS            5              5        81.429972\n",
      "5     1       ALO            6              6        81.429972\n",
      "6     1       OCO            7              7        81.429972\n",
      "7     1       HAM            8              8        81.429972\n",
      "8     1       HUL            9              9        81.429972\n",
      "9     1       STR           10             10        81.429972\n",
      "10    1       BOR           11             11        81.429972\n",
      "11    1       BEA           12             12        81.429972\n",
      "12    1       SAI           13             13        81.429972\n",
      "13    1       TSU           14             14        81.429972\n",
      "14    1       ANT           15             15        81.429972\n",
      "15    1       ALB           16             16        81.429972\n",
      "16    1       HAD           17             17        81.429972\n",
      "17    1       LAW           18             18        81.429972\n",
      "18    1       GAS           19             19        81.429972\n",
      "19    1       COL           20             20        81.429972\n",
      "20    2       VER            1              5        79.988879\n",
      "21    2       PIA            2             18        81.099152\n",
      "22    2       NOR            3             17        80.666309\n",
      "23    2       LEC            4              1        80.487268\n",
      "24    2       RUS            5             16        80.175075\n",
      "25    2       ALO            6             15        80.920925\n",
      "26    2       OCO            7              3        80.512368\n",
      "27    2       HAM            8             14        80.573297\n",
      "28    2       HUL            9              4        80.575407\n",
      "29    2       STR           10             12        79.557954\n",
      "Lap times (s):\n",
      "driver_id     ALB     ALO     ANT     BEA     BOR     COL     GAS     HAD  \\\n",
      "lap                                                                         \n",
      "1          81.430  81.430  81.430  81.430  81.430  81.430  81.430  81.430   \n",
      "2          80.357  80.921  79.843  79.502  80.694  80.201  80.504  80.407   \n",
      "3          79.898  80.677  80.123  79.820  80.314  79.945  80.702  80.141   \n",
      "4          81.121  80.568  80.792  80.993  79.967  80.311  79.629  80.421   \n",
      "5          80.937  80.394  81.107  80.773  80.905  79.817  80.436  80.574   \n",
      "6          79.558  80.369  80.430  79.543  80.948  80.663  80.407  80.033   \n",
      "7          80.270  80.814  79.636  80.145  79.975  80.049  80.166  80.883   \n",
      "8          81.559  80.980  80.519  80.086  80.106  80.535  80.728  79.705   \n",
      "9          80.604  80.438  81.052  79.918  80.526  80.089  80.046  79.513   \n",
      "10         80.065  80.151  80.706  80.716  80.503  80.293  80.668  80.429   \n",
      "11         80.286  80.422  79.499  80.077  80.612  80.651  80.111  80.890   \n",
      "12         80.184  79.316  79.652  80.445  80.088  80.323  81.029  80.202   \n",
      "13         80.430  80.019  80.652  80.348  80.407  79.671  80.914  80.481   \n",
      "14         80.238  79.656  80.644  80.880  80.217  80.112  80.173  79.938   \n",
      "15         80.861  80.319  80.816  80.628  81.274  80.561  81.130  79.051   \n",
      "16         81.084  80.258  80.097  80.283  81.264  80.540  79.899  80.042   \n",
      "17         80.758  80.555  80.956  79.938  81.288  80.787  81.289  80.318   \n",
      "18         80.145  80.509  80.399  79.678  80.243  80.718  80.497  80.247   \n",
      "19         80.476  80.801  79.565  80.282  79.965  80.173  80.307  80.928   \n",
      "20         80.067  80.306  80.980  79.802  80.232  80.806  80.033  79.402   \n",
      "21         80.736  80.739  80.283  80.784  80.270  80.449  80.479  80.634   \n",
      "22         81.126  79.581  80.177  80.916  80.923  81.519  80.768  79.970   \n",
      "23         80.179  80.221  79.880  80.152  80.350  79.330  80.529  80.097   \n",
      "24         80.643  80.652  79.911  79.453  80.553  79.629  80.821  80.014   \n",
      "25         80.300  81.007  80.808  79.429  80.333  80.441  80.156  80.358   \n",
      "\n",
      "driver_id     HAM     HUL     LAW     LEC     NOR     OCO     PIA     RUS  \\\n",
      "lap                                                                         \n",
      "1          81.430  81.430  81.430  81.430  81.430  81.430  81.430  81.430   \n",
      "2          80.573  80.575  80.322  80.487  80.666  80.512  81.099  80.175   \n",
      "3          80.538  80.714  79.887  80.902  79.735  79.774  80.005  80.523   \n",
      "4          80.756  80.222  80.134  80.240  80.352  80.132  80.673  80.084   \n",
      "5          80.034  80.621  81.406  80.710  80.281  79.247  80.388  80.672   \n",
      "6          81.048  79.440  80.993  79.999  80.254  80.071  81.040  80.450   \n",
      "7          80.157  80.884  80.372  80.435  80.280  79.755  80.637  80.255   \n",
      "8          80.592  80.453  80.201  80.132  81.015  80.393  80.160  80.171   \n",
      "9          80.146  80.463  80.471  80.404  79.913  80.092  81.248  80.175   \n",
      "10         80.006  80.218  80.382  80.705  80.445  80.011  80.663  79.936   \n",
      "11         80.790  79.931  80.209  79.983  80.396  79.701  80.540  80.717   \n",
      "12         80.175  79.831  79.615  80.861  81.231  80.374  80.627  79.845   \n",
      "13         80.984  79.854  79.863  79.952  78.854  79.784  80.778  80.568   \n",
      "14         80.916  80.068  80.487  79.853  80.305  80.773  80.357  80.405   \n",
      "15         80.469  80.069  80.180  79.711  79.970  80.007  80.556  79.750   \n",
      "16         80.428  79.921  80.281  80.576  80.542  80.272  81.220  79.967   \n",
      "17         80.378  80.393  79.913  80.185  80.153  81.027  80.609  79.582   \n",
      "18         80.323  80.039  80.454  80.496  80.539  80.142  80.428  80.601   \n",
      "19         80.020  79.710  81.211  80.548  80.729  80.052  80.451  80.740   \n",
      "20         80.567  80.235  80.300  80.439  80.524  80.705  80.824  80.128   \n",
      "21         80.072  80.874  80.610  79.217  80.291  80.110  79.129  80.211   \n",
      "22         80.448  79.544  79.951  80.031  79.539  80.164  80.236  79.508   \n",
      "23         79.365  81.024  79.637  79.976  80.162  80.778  80.397  80.257   \n",
      "24         80.276  80.863  80.074  80.414  80.180  80.246  79.371  80.983   \n",
      "25         80.846  80.599  80.226  80.094  80.429  79.557  80.799  80.764   \n",
      "\n",
      "driver_id     SAI     STR     TSU     VER  \n",
      "lap                                        \n",
      "1          81.430  81.430  81.430  81.430  \n",
      "2          80.367  79.558  80.177  79.989  \n",
      "3          81.559  80.102  80.155  81.381  \n",
      "4          79.836  80.440  79.720  80.212  \n",
      "5          80.220  79.944  79.883  80.814  \n",
      "6          80.494  80.597  80.953  80.300  \n",
      "7          80.096  80.120  80.724  80.656  \n",
      "8          80.671  80.722  79.936  80.043  \n",
      "9          80.071  79.864  79.546  80.480  \n",
      "10         80.134  80.433  80.642  80.028  \n",
      "11         80.675  80.109  80.653  80.194  \n",
      "12         80.229  80.324  80.519  80.630  \n",
      "13         80.389  80.218  80.617  79.645  \n",
      "14         80.892  79.922  80.354  80.012  \n",
      "15         80.802  80.114  80.258  80.590  \n",
      "16         80.425  80.484  80.526  81.101  \n",
      "17         80.540  80.230  80.409  80.302  \n",
      "18         80.083  80.387  80.599  79.937  \n",
      "19         80.320  80.924  81.050  80.502  \n",
      "20         80.224  80.596  80.987  79.981  \n",
      "21         80.447  79.823  79.766  80.614  \n",
      "22         80.239  80.862  80.669  80.891  \n",
      "23         80.861  79.318  80.053  81.186  \n",
      "24         80.591  80.255  80.272  79.729  \n",
      "25         81.385  80.977  79.843  81.216  \n",
      "Positions (1=leader):\n",
      "driver_id  ALB  ALO  ANT  BEA  BOR  COL  GAS  HAD  HAM  HUL  LAW  LEC  NOR  \\\n",
      "lap                                                                          \n",
      "1           16    6   15   12   11   20   19   17    8    9   18    4    3   \n",
      "2            2   15    8   11   19   20   13    7   14    4    6    1   17   \n",
      "3            5   14    6    8    9   20   19    2   12   11    4   16   17   \n",
      "4            6    2    1    9   10   20   19    5   13   12    4   16   17   \n",
      "5            4   14    5    8    9   20   19    3   12   11    2   16   17   \n",
      "6            9   15    4   10   19   20   12    3    6   13    8   17    2   \n",
      "7           10   14    2   11   19   20    7    1    5   13    9   16   17   \n",
      "8            7   14    1    2   10   20    3    6   12   19    5   16   17   \n",
      "9            6   14    7    9   10   20   19    5    3   12    4   16   17   \n",
      "10           5   15    6    9   10   20   19    4   13   12    3   16   17   \n",
      "11          16    6   15    3    4   20   10    2    8    9   18   11   12   \n",
      "12           2   14    7   10   19   20    4    6   12    3    5   16   17   \n",
      "13           7   17    8   12   19    3   13    6   15   14    2    4   11   \n",
      "14           9    4    5   11    7    1   19    3   14   13    8   17    2   \n",
      "15          10    4   11    8    7   20   19    2   15   14    9   16   17   \n",
      "16           7    3    8    4    5    1   19    2   13   12    6   16   17   \n",
      "17           7   15    8   10    3   20   19    6   13   12    5   17   18   \n",
      "18           1    2    9   10   19   20   12    8   14   13    7   16   17   \n",
      "19          16   10    3   13    5    8   11   17    7    6    2   15    9   \n",
      "20           1   14    8   10   17   18   12    7   19   13    6   15   20   \n",
      "21           2   19   15    3   11    6   10   17    5    4   18    9   12   \n",
      "22           8   15    9   11   18   19   20    7   14   13    6    1   16   \n",
      "23           7   14    8    4   10   20    5    6   12   19    2   16   17   \n",
      "24           8   14    9    3   19   20    4    7   13   12    6   16   17   \n",
      "25           5   14    6    8    9   20   19    4   12   11    3   16   17   \n",
      "\n",
      "driver_id  OCO  PIA  RUS  SAI  STR  TSU  VER  \n",
      "lap                                           \n",
      "1            7    2    5   13   10   14    1  \n",
      "2            3   18   16   10   12    9    5  \n",
      "3           13   18   15    3    1    7   10  \n",
      "4           14   18   15    8   11    7    3  \n",
      "5           13   18   15    7   10    6    1  \n",
      "6           14   18   16    7   11    5    1  \n",
      "7            4   18   15    6   12    3    8  \n",
      "8           13   18   15    9   11    8    4  \n",
      "9           13   18   15    2   11    8    1  \n",
      "10          14   18    1    8   11    7    2  \n",
      "11           7   17   19   13    5   14    1  \n",
      "12          13   18   15    9    1    8   11  \n",
      "13          16    5   18   10    1    9   20  \n",
      "14          15   18   16   10   20    6   12  \n",
      "15           5   18    3   12    1    6   13  \n",
      "16          14   18   15   10   20    9   11  \n",
      "17          14    1   16    9   11    2    4  \n",
      "18           3   18   15    5   11    4    6  \n",
      "19          19   18   12   14   20    4    1  \n",
      "20           3   16    2    4   11    9    5  \n",
      "21           7   16    8   13   20   14    1  \n",
      "22           3   17    2    4   12   10    5  \n",
      "23          13   18   15    3    1    9   11  \n",
      "24           1   18   15    2   11   10    5  \n",
      "25          13   18   15    1   10    7    2  \n",
      "Predicted lap-time z-score stats per lap:\n",
      "    lap     min_z     max_z    mean_z\n",
      "0     2 -0.236110 -0.040514 -0.132682\n",
      "1     3 -0.207519  0.015828 -0.132884\n",
      "2     4 -0.220545 -0.037831 -0.134694\n",
      "3     5 -0.267380 -0.002881 -0.119013\n",
      "4     6 -0.243684 -0.046791 -0.128633\n",
      "5     7 -0.219666 -0.066844 -0.136483\n",
      "6     8 -0.211192  0.015764 -0.121801\n",
      "7     9 -0.234807 -0.022287 -0.144137\n",
      "8    10 -0.182901 -0.087412 -0.131429\n",
      "9    11 -0.236422 -0.066069 -0.135638\n",
      "10   12 -0.258916 -0.024318 -0.141430\n",
      "11   13 -0.315488 -0.054596 -0.148013\n",
      "12   14 -0.217229 -0.062922 -0.137148\n",
      "13   15 -0.291393 -0.019097 -0.131549\n",
      "14   16 -0.187545 -0.020377 -0.118743\n",
      "15   17 -0.226316 -0.017264 -0.116271\n",
      "16   18 -0.214511 -0.087155 -0.135535\n",
      "17   19 -0.228412 -0.026834 -0.121510\n",
      "18   20 -0.248377 -0.054272 -0.131410\n",
      "19   21 -0.281734 -0.068138 -0.141218\n",
      "20   22 -0.235425  0.010951 -0.131882\n",
      "21   23 -0.258701 -0.029857 -0.152140\n",
      "22   24 -0.252210 -0.054798 -0.144944\n",
      "23   25 -0.244995 -0.005533 -0.116549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example simulation: Monaco with supplied grid and event laps\n",
    "monaco_track = 'monaco' if 'monaco' in track_scalers else list(track_scalers.keys())[0]\n",
    "driver_ids = [\n",
    "    'VER','PIA','NOR','LEC','RUS','ALO','OCO','HAM','HUL','STR',\n",
    "    'BOR','BEA','SAI','TSU','ANT','ALB','HAD','LAW','GAS','COL',\n",
    "]\n",
    "teams = [\n",
    "    'red_bull','mclaren','mclaren','ferrari','mercedes','aston_martin','haas','ferrari','sauber','aston_martin',\n",
    "    'sauber','haas','williams','red_bull','mercedes','williams','racing_bulls','racing_bulls','alpine','alpine',\n",
    "]\n",
    "sc_laps = [12, 13, 14, 15]\n",
    "vsc_laps = []\n",
    "rain_laps = [22, 23, 24]\n",
    "drs_laps = list(range(3, 26))\n",
    "\n",
    "sim_df, lap_time_table, position_table, debug_df = simulate_race(\n",
    "    model,\n",
    "    track_id=monaco_track,\n",
    "    total_laps=25,\n",
    "    num_drivers=20,\n",
    "    drivers=driver_ids,\n",
    "    teams=teams,\n",
    "    safety_car_laps=sc_laps,\n",
    "    vsc_laps=vsc_laps,\n",
    "    rain_laps=rain_laps,\n",
    "    drs_enabled_laps=drs_laps,\n",
    ")\n",
    "print(sim_df.head(30))\n",
    "print(\"Lap times (s):\")\n",
    "print(lap_time_table.round(3))\n",
    "print(\"Positions (1=leader):\")\n",
    "print(position_table.astype(int))\n",
    "print(\"Predicted lap-time z-score stats per lap:\")\n",
    "print(debug_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
