{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bd64b1",
   "metadata": {},
   "source": [
    "\n",
    "# Lap Context Transformer\n",
    "\n",
    "Train a transformer that ingests every lap of a race up to lap `t` and predicts the next lap (`t+1`) lap time and position for all drivers. Each batch may contain races of different lengths; we pad shorter contexts and mask padded tokens during attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c9a6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44682) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ekazuki/Library/Python/3.14/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ekazuki/Library/Python/3.14/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(44685) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn tqdm\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef7881",
   "metadata": {},
   "source": [
    "\n",
    "## Imports & configuration\n",
    "Define the training configuration, seed everything, and set up helper functions for statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b71fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=DEVICE)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "def ensure_pos_std(series: pd.Series) -> float:\n",
    "    std = float(series.std())\n",
    "    return std if std > 1e-6 else 1.0\n",
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    dataset_path: Path = Path('fastf1_lap_dataset2.csv')\n",
    "    max_drivers: int = 20\n",
    "    min_laps_per_session: int = 5\n",
    "    train_years: Tuple[int, ...] = (2018, 2019, 2020, 2021)\n",
    "    val_years: Tuple[int, ...] = (2023,)\n",
    "    test_years: Tuple[int, ...] = (2024, 2025)\n",
    "    batch_size: int = 2\n",
    "    grad_accum_steps: int = 8\n",
    "    num_epochs: int = 1\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    max_train_steps_per_epoch: Optional[int] = None\n",
    "    max_val_steps: Optional[int] = None\n",
    "    seed: int = 42\n",
    "    debug_sessions: Optional[int] = None\n",
    "CONFIG = TrainerConfig()\n",
    "np.random.seed(CONFIG.seed)\n",
    "torch.manual_seed(CONFIG.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863b89b",
   "metadata": {},
   "source": [
    "\n",
    "## Load and preprocess the lap dataset\n",
    "Clean missing values, fill lagged lap times, and derive helper columns for gaps, tyre age, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0542b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>circuit_id</th>\n",
       "      <th>total_race_laps</th>\n",
       "      <th>year</th>\n",
       "      <th>session_name</th>\n",
       "      <th>grid_position</th>\n",
       "      <th>current_position</th>\n",
       "      <th>gap_to_leader_s</th>\n",
       "      <th>gap_to_ahead_s</th>\n",
       "      <th>...</th>\n",
       "      <th>team_name</th>\n",
       "      <th>virtual_sc_this_lap</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>lap_time_prev1</th>\n",
       "      <th>lap_time_prev2</th>\n",
       "      <th>pit_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALO</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>55</td>\n",
       "      <td>2018</td>\n",
       "      <td>Race</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.062</td>\n",
       "      <td>2.134</td>\n",
       "      <td>...</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>False</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7</td>\n",
       "      <td>272</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALO</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>55</td>\n",
       "      <td>2018</td>\n",
       "      <td>Race</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.996</td>\n",
       "      <td>1.680</td>\n",
       "      <td>...</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>False</td>\n",
       "      <td>38.2</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>False</td>\n",
       "      <td>1.5</td>\n",
       "      <td>225</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALO</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>55</td>\n",
       "      <td>2018</td>\n",
       "      <td>Race</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.340</td>\n",
       "      <td>0.813</td>\n",
       "      <td>...</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1</td>\n",
       "      <td>268</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALO</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>55</td>\n",
       "      <td>2018</td>\n",
       "      <td>Race</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.010</td>\n",
       "      <td>0.432</td>\n",
       "      <td>...</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>False</td>\n",
       "      <td>37.7</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>267</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALO</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>yas_marina</td>\n",
       "      <td>55</td>\n",
       "      <td>2018</td>\n",
       "      <td>Race</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.847</td>\n",
       "      <td>0.613</td>\n",
       "      <td>...</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>False</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>105.3555</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  driver_id  team_id  circuit_id  total_race_laps  year session_name  \\\n",
       "0       ALO  mclaren  yas_marina               55  2018         Race   \n",
       "1       ALO  mclaren  yas_marina               55  2018         Race   \n",
       "2       ALO  mclaren  yas_marina               55  2018         Race   \n",
       "3       ALO  mclaren  yas_marina               55  2018         Race   \n",
       "4       ALO  mclaren  yas_marina               55  2018         Race   \n",
       "\n",
       "   grid_position  current_position  gap_to_leader_s  gap_to_ahead_s  ...  \\\n",
       "0           15.0              15.0           26.062           2.134  ...   \n",
       "1           14.0              14.0           16.996           1.680  ...   \n",
       "2           14.0              14.0           16.340           0.813  ...   \n",
       "3           14.0              14.0            8.010           0.432  ...   \n",
       "4           14.0              14.0           12.847           0.613  ...   \n",
       "\n",
       "   team_name  virtual_sc_this_lap humidity  pressure  rainfall  wind_speed  \\\n",
       "0    McLaren                False     38.7    1012.8     False         0.7   \n",
       "1    McLaren                False     38.2    1012.7     False         1.5   \n",
       "2    McLaren                False     37.5    1012.7     False         1.1   \n",
       "3    McLaren                False     37.7    1012.8     False         0.8   \n",
       "4    McLaren                False     37.5    1012.8     False         1.3   \n",
       "\n",
       "   wind_direction  lap_time_prev1  lap_time_prev2 pit_flag  \n",
       "0             272        105.3555        105.3555     True  \n",
       "1             225        105.3555        105.3555    False  \n",
       "2             268        105.3555        105.3555    False  \n",
       "3             267        105.3555        105.3555    False  \n",
       "4               0        105.3555        105.3555    False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_lap_dataframe(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required = {'session_key', 'driver_id', 'lap_number'}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing columns: {missing}')\n",
    "    df = df.dropna(subset=list(required)).copy()\n",
    "    df['lap_number'] = df['lap_number'].astype(int)\n",
    "    df = df.sort_values(['session_key', 'driver_id', 'lap_number'])\n",
    "\n",
    "    # Fill various gaps\n",
    "    df['gap_to_leader_s'] = df['gap_to_leader_s'].fillna(0)\n",
    "    df['gap_to_ahead_s'] = df['gap_to_ahead_s'].fillna(0)\n",
    "    df['current_position'] = df['current_position'].fillna(df['lap_number'])\n",
    "    df['grid_position'] = df.groupby(['session_key', 'driver_id'])['grid_position'].transform(lambda s: s.fillna(s.iloc[0]))\n",
    "    df['grid_position'] = df['grid_position'].fillna(df['current_position'])\n",
    "    df['grid_position'] = df['grid_position'].fillna(df['lap_number'])\n",
    "    df['laps_on_current_tyre'] = df['laps_on_current_tyre'].fillna(1)\n",
    "    df['lap_time_s'] = df.groupby('session_key')['lap_time_s'].transform(lambda s: s.fillna(s.median()))\n",
    "    df['lap_time_s'] = df['lap_time_s'].fillna(df['lap_time_s'].median())\n",
    "\n",
    "    for col in ['track_temperature', 'air_temperature', 'humidity', 'wind_speed', 'pressure']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    for col in ['drs_enabled', 'safety_car_this_lap', 'virtual_sc_this_lap', 'rainfall', 'has_rain']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(False)\n",
    "    df['tyre_compound'] = df['tyre_compound'].fillna('UNKNOWN')\n",
    "\n",
    "    df['lap_time_prev1'] = df.groupby(['session_key', 'driver_id'])['lap_time_s'].shift(1)\n",
    "    df['lap_time_prev2'] = df.groupby(['session_key', 'driver_id'])['lap_time_s'].shift(2)\n",
    "    df['lap_time_prev1'] = df['lap_time_prev1'].fillna(df['lap_time_s'])\n",
    "    df['lap_time_prev2'] = df['lap_time_prev2'].fillna(df['lap_time_s'])\n",
    "    df['pit_flag'] = False\n",
    "    for (session_key, driver_id), group in df.groupby(['session_key', 'driver_id']):\n",
    "        order = group.sort_values('lap_number')\n",
    "        tyre_diff = order['laps_on_current_tyre'].diff()\n",
    "        compound_change = order['tyre_compound'].ne(order['tyre_compound'].shift(1))\n",
    "        pits = (tyre_diff < 0) | compound_change.fillna(False)\n",
    "        df.loc[order.index, 'pit_flag'] = pits.fillna(False)\n",
    "    return df\n",
    "\n",
    "raw_df = load_lap_dataframe(CONFIG.dataset_path)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2d859",
   "metadata": {},
   "source": [
    "\n",
    "## Track/weather scalers & vocabularies\n",
    "Compute per-track mean/std for lap times and gaps, global weather scalers, and integer vocabularies for drivers/teams/circuits/compounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b3307e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_track_scalers(df: pd.DataFrame) -> Dict[str, Dict[str, Tuple[float, float]]]:\n",
    "    stats = {}\n",
    "    for circuit_id, group in df.groupby('circuit_id'):\n",
    "        lap_series = group['lap_time_s']\n",
    "        gap_leader = np.log1p(group['gap_to_leader_s'])\n",
    "        gap_ahead = np.log1p(group['gap_to_ahead_s'])\n",
    "        stats[circuit_id] = {\n",
    "            'lap_time_s': (float(lap_series.mean()), ensure_pos_std(lap_series)),\n",
    "            'gap_to_leader_s': (float(gap_leader.mean()), ensure_pos_std(gap_leader)),\n",
    "            'gap_to_ahead_s': (float(gap_ahead.mean()), ensure_pos_std(gap_ahead)),\n",
    "        }\n",
    "    if not stats:\n",
    "        raise ValueError('No circuits found for scalers')\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_weather_scaler(df: pd.DataFrame) -> Dict[str, Tuple[float, float]]:\n",
    "    scalers = {}\n",
    "    for col in ['track_temperature', 'air_temperature', 'humidity', 'wind_speed', 'pressure']:\n",
    "        series = df[col].astype(float)\n",
    "        scalers[col] = (float(series.mean()), ensure_pos_std(series))\n",
    "    return scalers\n",
    "\n",
    "track_scalers = compute_track_scalers(raw_df)\n",
    "weather_scaler = compute_weather_scaler(raw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179b945",
   "metadata": {},
   "source": [
    "\n",
    "## Session tensor builder\n",
    "Convert each race (session) into dense tensors: `[laps, max_drivers, dynamics]`, global lap features, categorical tokens, and normalized targets. Only races with at least `min_laps_per_session` laps are kept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0a9fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sessions: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 168/168 [00:04<00:00, 35.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorized sessions: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SessionTensor:\n",
    "    session_key: str\n",
    "    year: int\n",
    "    track_token: int\n",
    "    dynamic_numeric: np.ndarray\n",
    "    global_numeric: np.ndarray\n",
    "    rank_tokens: np.ndarray\n",
    "    compound_tokens: np.ndarray\n",
    "    alive_mask: np.ndarray\n",
    "    lap_time_norm: np.ndarray\n",
    "    position_norm: np.ndarray\n",
    "    driver_tokens: np.ndarray\n",
    "    team_tokens: np.ndarray\n",
    "    static_numeric: np.ndarray\n",
    "class SessionTensorBuilder:\n",
    "    def __init__(self, cfg: TrainerConfig, vocab: LapVocabulary, track_scalers, weather_scaler):\n",
    "        self.cfg = cfg\n",
    "        self.vocab = vocab\n",
    "        self.track_scalers = track_scalers\n",
    "        self.weather_scaler = weather_scaler\n",
    "    def _zscore(self, value: float, mean: float, std: float) -> float:\n",
    "        if pd.isna(value):\n",
    "            return 0.0\n",
    "        return float((value - mean) / (std if std > 1e-6 else 1.0))\n",
    "    def build(self, df: pd.DataFrame) -> List[SessionTensor]:\n",
    "        sessions = []\n",
    "        for idx, (session_key, sdf) in enumerate(tqdm(df.groupby('session_key', sort=False), desc='Sessions')):\n",
    "            if CONFIG.debug_sessions and idx >= CONFIG.debug_sessions:\n",
    "                break\n",
    "            sdf = sdf.sort_values(['lap_number', 'driver_id']).copy()\n",
    "            max_lap = int(sdf['lap_number'].max())\n",
    "            if max_lap < CONFIG.min_laps_per_session:\n",
    "                continue\n",
    "            drivers = sorted(sdf['driver_id'].unique().tolist())[: CONFIG.max_drivers]\n",
    "            driver_slots = {drv: slot for slot, drv in enumerate(drivers)}\n",
    "            slots = CONFIG.max_drivers\n",
    "            dyn_dim = 12\n",
    "            dynamic = np.zeros((max_lap, slots, dyn_dim), dtype=np.float32)\n",
    "            rank_tokens = np.zeros((max_lap, slots), dtype=np.int64)\n",
    "            compound_tokens = np.zeros((max_lap, slots), dtype=np.int64)\n",
    "            alive = np.zeros((max_lap, slots), dtype=np.float32)\n",
    "            lap_time_norm = np.zeros((max_lap, slots), dtype=np.float32)\n",
    "            global_feats = np.zeros((max_lap, 8), dtype=np.float32)\n",
    "            driver_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "            team_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "            static_numeric = np.zeros((slots, 2), dtype=np.float32)\n",
    "            circuit_id = sdf['circuit_id'].iloc[0]\n",
    "            track_stats = self.track_scalers.get(circuit_id, next(iter(self.track_scalers.values())))\n",
    "            track_token = self.vocab.track_to_idx.get(circuit_id, 0)\n",
    "            total_ref = max(max_lap, int(sdf['total_race_laps'].dropna().max() or max_lap))\n",
    "            for driver_id, rows in sdf.groupby('driver_id'):\n",
    "                if driver_id not in driver_slots:\n",
    "                    continue\n",
    "                slot = driver_slots[driver_id]\n",
    "                driver_tokens[slot] = self.vocab.driver_to_idx.get(driver_id, 0)\n",
    "                team_tokens[slot] = self.vocab.team_to_idx.get(rows['team_id'].iloc[0], 0)\n",
    "                static_numeric[slot, 0] = float(rows['grid_position'].iloc[0] / CONFIG.max_drivers)\n",
    "                static_numeric[slot, 1] = float(rows['year'].iloc[0] - 2018) / 10.0\n",
    "                for _, row in rows.iterrows():\n",
    "                    lap_idx = int(row['lap_number']) - 1\n",
    "                    pos_norm = (float(row['current_position']) - 1) / max(1, CONFIG.max_drivers - 1)\n",
    "                    dynamic[lap_idx, slot, 0] = pos_norm\n",
    "                    dynamic[lap_idx, slot, 1] = float(row['grid_position']) / CONFIG.max_drivers\n",
    "                    lap_mean, lap_std = track_stats['lap_time_s']\n",
    "                    lap_norm = self._zscore(row['lap_time_s'], lap_mean, lap_std)\n",
    "                    dynamic[lap_idx, slot, 2] = lap_norm\n",
    "                    dynamic[lap_idx, slot, 3] = self._zscore(row['lap_time_prev1'], lap_mean, lap_std)\n",
    "                    dynamic[lap_idx, slot, 4] = self._zscore(row['lap_time_prev2'], lap_mean, lap_std)\n",
    "                    gap_mean, gap_std = track_stats['gap_to_leader_s']\n",
    "                    ahead_mean, ahead_std = track_stats['gap_to_ahead_s']\n",
    "                    dynamic[lap_idx, slot, 5] = self._zscore(np.log1p(row['gap_to_leader_s']), gap_mean, gap_std)\n",
    "                    dynamic[lap_idx, slot, 6] = self._zscore(np.log1p(row['gap_to_ahead_s']), ahead_mean, ahead_std)\n",
    "                    dynamic[lap_idx, slot, 7] = float(row['laps_on_current_tyre']) / 50.0\n",
    "                    dynamic[lap_idx, slot, 8] = float(row['pit_flag'])\n",
    "                    dynamic[lap_idx, slot, 9] = float(row['drs_enabled'])\n",
    "                    dynamic[lap_idx, slot, 10] = float(row['safety_car_this_lap'])\n",
    "                    dynamic[lap_idx, slot, 11] = float(row['virtual_sc_this_lap'])\n",
    "                    compound_tokens[lap_idx, slot] = self.vocab.compound_to_idx.get(row['tyre_compound'], 0)\n",
    "                    rank_tokens[lap_idx, slot] = int(row['current_position']) - 1\n",
    "                    lap_time_norm[lap_idx, slot] = lap_norm\n",
    "                    alive[lap_idx, slot] = 1.0\n",
    "            for lap_idx in range(max_lap):\n",
    "                lap_no = lap_idx + 1\n",
    "                frac = lap_no / total_ref\n",
    "                remaining = (total_ref - lap_no) / total_ref\n",
    "                global_feats[lap_idx, 0] = frac\n",
    "                global_feats[lap_idx, 1] = remaining\n",
    "                row = sdf[sdf['lap_number'] == lap_no].iloc[0]\n",
    "                for g_idx, col in enumerate(['track_temperature', 'air_temperature', 'humidity', 'wind_speed'], start=2):\n",
    "                    mean, std = self.weather_scaler[col]\n",
    "                    global_feats[lap_idx, g_idx] = self._zscore(row[col], mean, std)\n",
    "                global_feats[lap_idx, 6] = float(row['has_rain'])\n",
    "                p_mean, p_std = self.weather_scaler['pressure']\n",
    "                global_feats[lap_idx, 7] = self._zscore(row['pressure'], p_mean, p_std)\n",
    "            position_norm = rank_tokens.astype(np.float32)\n",
    "            if CONFIG.max_drivers > 1:\n",
    "                position_norm /= (CONFIG.max_drivers - 1)\n",
    "            sessions.append(SessionTensor(\n",
    "                session_key=session_key,\n",
    "                year=int(sdf['year'].iloc[0]),\n",
    "                track_token=track_token,\n",
    "                dynamic_numeric=dynamic,\n",
    "                global_numeric=global_feats,\n",
    "                rank_tokens=rank_tokens,\n",
    "                compound_tokens=compound_tokens,\n",
    "                alive_mask=alive,\n",
    "                lap_time_norm=lap_time_norm,\n",
    "                position_norm=position_norm,\n",
    "                driver_tokens=driver_tokens,\n",
    "                team_tokens=team_tokens,\n",
    "                static_numeric=static_numeric,\n",
    "            ))\n",
    "        return sessions\n",
    "builder = SessionTensorBuilder(CONFIG, vocab, track_scalers, weather_scaler)\n",
    "session_tensors = builder.build(raw_df)\n",
    "print(f\"Tensorized sessions: {len(session_tensors)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3283e",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset: full context, next-lap target\n",
    "Each sample contains all laps up to `t` and predicts lap `t+1`. We pad contexts per batch and build masks automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62519c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4837 | Val: 1412\n"
     ]
    }
   ],
   "source": [
    "class LapContextDataset(Dataset):\n",
    "    def __init__(self, sessions: Sequence[SessionTensor], cfg: TrainerConfig, years: Tuple[int, ...]):\n",
    "        self.sessions = [s for s in sessions if s.year in years]\n",
    "        self.cfg = cfg\n",
    "        self.indices: List[Tuple[int, int]] = []\n",
    "        for sess_idx, sess in enumerate(self.sessions):\n",
    "            T = sess.dynamic_numeric.shape[0]\n",
    "            for target_idx in range(1, T):\n",
    "                self.indices.append((sess_idx, target_idx))\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        sess_idx, target_idx = self.indices[idx]\n",
    "        sess = self.sessions[sess_idx]\n",
    "        ctx_slice = slice(0, target_idx)\n",
    "        return {\n",
    "            'dynamic': torch.from_numpy(sess.dynamic_numeric[ctx_slice]).float(),\n",
    "            'global': torch.from_numpy(sess.global_numeric[ctx_slice]).float(),\n",
    "            'compound_tokens': torch.from_numpy(sess.compound_tokens[ctx_slice]).long(),\n",
    "            'rank_tokens': torch.from_numpy(sess.rank_tokens[ctx_slice]).long(),\n",
    "            'alive_mask': torch.from_numpy(sess.alive_mask[ctx_slice]).float(),\n",
    "            'context_length': torch.tensor(target_idx, dtype=torch.long),\n",
    "            'driver_tokens': torch.from_numpy(sess.driver_tokens).long(),\n",
    "            'team_tokens': torch.from_numpy(sess.team_tokens).long(),\n",
    "            'static_numeric': torch.from_numpy(sess.static_numeric).float(),\n",
    "            'track_token': torch.tensor(sess.track_token).long(),\n",
    "            'target_lap_time': torch.from_numpy(sess.lap_time_norm[target_idx]).float(),\n",
    "            'target_position': torch.from_numpy(sess.position_norm[target_idx]).float(),\n",
    "            'target_alive': torch.from_numpy(sess.alive_mask[target_idx]).float(),\n",
    "        }\n",
    "def pad_tensor(seq: torch.Tensor, target_len: int) -> torch.Tensor:\n",
    "    if seq.shape[0] == target_len:\n",
    "        return seq\n",
    "    pad_shape = (target_len - seq.shape[0],) + tuple(seq.shape[1:])\n",
    "    pad_tensor = torch.zeros(pad_shape, dtype=seq.dtype)\n",
    "    return torch.cat([seq, pad_tensor], dim=0)\n",
    "def collate_context(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    max_len = max(int(item['context_length']) for item in batch)\n",
    "    out: Dict[str, torch.Tensor] = {}\n",
    "    for key in ['dynamic', 'global', 'compound_tokens', 'rank_tokens', 'alive_mask']:\n",
    "        out[key] = torch.stack([pad_tensor(item[key], max_len) for item in batch], dim=0)\n",
    "    out['context_length'] = torch.stack([item['context_length'] for item in batch], dim=0)\n",
    "    out['driver_tokens'] = torch.stack([item['driver_tokens'] for item in batch], dim=0)\n",
    "    out['team_tokens'] = torch.stack([item['team_tokens'] for item in batch], dim=0)\n",
    "    out['static_numeric'] = torch.stack([item['static_numeric'] for item in batch], dim=0)\n",
    "    out['track_token'] = torch.stack([item['track_token'] for item in batch], dim=0)\n",
    "    out['target_lap_time'] = torch.stack([item['target_lap_time'] for item in batch], dim=0)\n",
    "    out['target_position'] = torch.stack([item['target_position'] for item in batch], dim=0)\n",
    "    out['target_alive'] = torch.stack([item['target_alive'] for item in batch], dim=0)\n",
    "    return out\n",
    "train_dataset = LapContextDataset(session_tensors, CONFIG, CONFIG.train_years)\n",
    "val_dataset = LapContextDataset(session_tensors, CONFIG, CONFIG.val_years)\n",
    "print(f\"Train samples: {len(train_dataset)} | Val: {len(val_dataset)}\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_context,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_context,\n",
    "    num_workers=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35739b",
   "metadata": {},
   "source": [
    "\n",
    "## Lap context transformer\n",
    "Driver tokens are concatenated with lap/slot embeddings, dynamic scalars, and global features, then passed through a transformer encoder. We gather the last-lap tokens to predict the next lap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6596ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LapContextTransformer(nn.Module):\n",
    "    def __init__(self, cfg: TrainerConfig, vocab: LapVocabulary, dyn_dim: int, global_dim: int, static_dim: int):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.driver_emb = nn.Embedding(vocab.num_drivers + 1, 32, padding_idx=0)\n",
    "        self.team_emb = nn.Embedding(vocab.num_teams + 1, 16, padding_idx=0)\n",
    "        self.compound_emb = nn.Embedding(vocab.num_compounds + 1, 8, padding_idx=0)\n",
    "        self.rank_emb = nn.Embedding(cfg.max_drivers + 1, 8, padding_idx=0)\n",
    "        self.slot_emb = nn.Embedding(cfg.max_drivers, 8)\n",
    "        self.track_emb = nn.Embedding(vocab.num_tracks + 1, 16, padding_idx=0)\n",
    "        self.lap_pos_emb = nn.Embedding(256, 32)\n",
    "        self.static_proj = nn.Linear(static_dim + 32 + 16, 64)\n",
    "        self.global_proj = nn.Linear(global_dim + 16 + 32, 64)\n",
    "        self.token_proj = nn.Linear(dyn_dim + 8 + 8 + 8 + 64 + 64, 256)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=1024, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.time_head = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "        self.position_head = nn.Sequential(nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        B, T_ctx, N, _ = batch['dynamic'].shape\n",
    "        dyn = batch['dynamic'].to(DEVICE)\n",
    "        if DEVICE.type == \"mps\" and dyn.device.type != \"mps\":\n",
    "            raise RuntimeError(\"Expected MPS tensors; got CPU (fallback). Disable fallback or reduce batch size.\")\n",
    "        rank_tokens = batch['rank_tokens'].to(DEVICE)\n",
    "        compound_tokens = batch['compound_tokens'].to(DEVICE)\n",
    "        alive = batch['alive_mask'].to(DEVICE)\n",
    "        global_feats = batch['global'].to(DEVICE)\n",
    "        track_tokens = batch['track_token'].to(DEVICE)\n",
    "        driver_tokens = batch['driver_tokens'].to(DEVICE)\n",
    "        team_tokens = batch['team_tokens'].to(DEVICE)\n",
    "        static_numeric = batch['static_numeric'].to(DEVICE)\n",
    "        context_lengths = batch['context_length'].to(DEVICE)\n",
    "        driver_emb = self.driver_emb(driver_tokens)\n",
    "        team_emb = self.team_emb(team_tokens)\n",
    "        static_feat = torch.cat([static_numeric, driver_emb, team_emb], dim=-1)\n",
    "        static_feat = self.static_proj(static_feat).unsqueeze(1).expand(-1, T_ctx, -1, -1)\n",
    "        lap_positions = torch.arange(T_ctx, device=DEVICE).view(1, T_ctx).expand(B, T_ctx)\n",
    "        lap_emb = self.lap_pos_emb(torch.clamp(lap_positions, max=self.lap_pos_emb.num_embeddings - 1))\n",
    "        track_emb = self.track_emb(track_tokens).unsqueeze(1).expand(-1, T_ctx, -1)\n",
    "        global_cat = torch.cat([global_feats, track_emb, lap_emb], dim=-1)\n",
    "        global_feat = self.global_proj(global_cat).unsqueeze(2).expand(-1, -1, N, -1)\n",
    "        slot_idx = torch.arange(N, device=DEVICE).view(1, 1, N).expand(B, T_ctx, N)\n",
    "        slot_emb = self.slot_emb(torch.clamp(slot_idx, max=self.cfg.max_drivers - 1))\n",
    "        rank_emb = self.rank_emb(torch.clamp(rank_tokens, max=self.cfg.max_drivers))\n",
    "        compound_emb = self.compound_emb(compound_tokens)\n",
    "        tokens = torch.cat([dyn, rank_emb, compound_emb, slot_emb, static_feat, global_feat], dim=-1)\n",
    "        tokens = self.token_proj(tokens)\n",
    "        tokens = tokens.view(B, T_ctx * N, -1)\n",
    "        key_padding = ~(alive.view(B, T_ctx * N).bool())\n",
    "        encoded = self.encoder(tokens, src_key_padding_mask=key_padding)\n",
    "        last_idx = torch.clamp(context_lengths - 1, min=0)\n",
    "        base = last_idx * N\n",
    "        gather = base.unsqueeze(1) + torch.arange(N, device=DEVICE)\n",
    "        gather = torch.clamp(gather, max=T_ctx * N - 1)\n",
    "        encoded_last = torch.gather(encoded, 1, gather.unsqueeze(-1).expand(-1, -1, encoded.shape[-1]))\n",
    "        pred_time = self.time_head(encoded_last).squeeze(-1)\n",
    "        pred_pos = self.position_head(encoded_last).squeeze(-1)\n",
    "        return {'lap_time': pred_time, 'position': pred_pos}\n",
    "model = LapContextTransformer(\n",
    "    CONFIG,\n",
    "    vocab,\n",
    "    dyn_dim=session_tensors[0].dynamic_numeric.shape[-1],\n",
    "    global_dim=session_tensors[0].global_numeric.shape[-1],\n",
    "    static_dim=session_tensors[0].static_numeric.shape[-1],\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a53f1b",
   "metadata": {},
   "source": [
    "\n",
    "## Training & evaluation loops\n",
    "Use SmoothL1 loss on lap time and position, mask retired/padded drivers, and average per batch. The evaluation computes the same metrics without gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4ef02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.SmoothL1Loss(reduction='none')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, weight_decay=CONFIG.weight_decay)\n",
    "\n",
    "def step(model, batch, train=True):\n",
    "    preds = model(batch)\n",
    "    alive = batch['target_alive'].to(DEVICE)\n",
    "    time_tgt = batch['target_lap_time'].to(DEVICE)\n",
    "    pos_tgt = batch['target_position'].to(DEVICE)\n",
    "\n",
    "    time_loss = loss_fn(preds['lap_time'], time_tgt)\n",
    "    pos_loss = loss_fn(preds['position'], pos_tgt)\n",
    "    denom = max(alive.sum().item(), 1.0)\n",
    "    time_loss = (time_loss * alive).sum() / denom\n",
    "    pos_loss = (pos_loss * alive).sum() / denom\n",
    "    total = time_loss + pos_loss\n",
    "\n",
    "    if train:\n",
    "        back_loss = total / max(CONFIG.grad_accum_steps, 1)\n",
    "        back_loss.backward()\n",
    "\n",
    "    return {'time_loss': time_loss.item(), 'position_loss': pos_loss.item(), 'total': total.item()}\n",
    "\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    metrics = []\n",
    "    iterator = tqdm(loader, desc='train' if train else 'val', leave=False)\n",
    "    steps = 0\n",
    "    optim_step = 0\n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for batch in iterator:\n",
    "            stats = step(model, batch, train=train)\n",
    "            iterator.set_postfix({k: f\"{v:.3f}\" for k, v in stats.items()})\n",
    "            metrics.append(stats)\n",
    "            steps += 1\n",
    "\n",
    "            if train and (optim_step + 1) % max(CONFIG.grad_accum_steps, 1) == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            if train:\n",
    "                optim_step += 1\n",
    "\n",
    "            limit = CONFIG.max_train_steps_per_epoch if train else CONFIG.max_val_steps\n",
    "            if limit and steps >= limit:\n",
    "                break\n",
    "\n",
    "    if train and optim_step % max(CONFIG.grad_accum_steps, 1) != 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if not metrics:\n",
    "        return {}\n",
    "    return {k: float(np.mean([m[k] for m in metrics])) for k in metrics[0]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e48bf",
   "metadata": {},
   "source": [
    "\n",
    "## Train the model\n",
    "Adjust `num_epochs`, `max_train_steps_per_epoch`, or `max_val_steps` in CONFIG if you want shorter runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2d455d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m val_history = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, CONFIG.num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_metrics = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     val_metrics = run_epoch(val_loader, train=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m     train_history.append(train_metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(loader, train)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(train):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         stats = \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m         iterator.set_postfix({k: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m stats.items()})\n\u001b[32m     36\u001b[39m         metrics.append(stats)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mstep\u001b[39m\u001b[34m(model, batch, train)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(model, batch, train=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      5\u001b[39m     preds = model(batch)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     alive = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_alive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     time_tgt = batch[\u001b[33m'\u001b[39m\u001b[33mtarget_lap_time\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n\u001b[32m      8\u001b[39m     pos_tgt = batch[\u001b[33m'\u001b[39m\u001b[33mtarget_position\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_history = []\n",
    "val_history = []\n",
    "for epoch in range(1, CONFIG.num_epochs + 1):\n",
    "    train_metrics = run_epoch(train_loader, train=True)\n",
    "    val_metrics = run_epoch(val_loader, train=False)\n",
    "    train_history.append(train_metrics)\n",
    "    val_history.append(val_metrics)\n",
    "    print(f\"Epoch {epoch}: train={train_metrics} | val={val_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4620bc",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate (optional)\n",
    "Compute validation MAE on the normalized lap times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bb964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation lap-time MAE (normalized units): nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "mae_vals = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        stats = step(model, batch, train=False)\n",
    "        mae_vals.append(stats['time_loss'])\n",
    "        if CONFIG.max_val_steps and batch_idx + 1 >= CONFIG.max_val_steps:\n",
    "            break\n",
    "val_mae = float(np.mean(mae_vals)) if mae_vals else float('nan')\n",
    "print(f\"Validation lap-time MAE (normalized units): {val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ea9c3",
   "metadata": {},
   "source": [
    "\n",
    "## Save checkpoint\n",
    "Persist the trained weights along with config and vocab metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f98eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': CONFIG.__dict__,\n",
    "    'vocab': {\n",
    "        'driver_to_idx': vocab.driver_to_idx,\n",
    "        'team_to_idx': vocab.team_to_idx,\n",
    "        'compound_to_idx': vocab.compound_to_idx,\n",
    "        'track_to_idx': vocab.track_to_idx,\n",
    "    },\n",
    "}\n",
    "ckpt_path = Path('models/lap_context_transformer.ckpt')\n",
    "torch.save(checkpoint, ckpt_path)\n",
    "print(f'Saved checkpoint to {ckpt_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa00999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Simple lap-by-lap simulation using the trained model and real drivers with light dynamics.\n",
    "def simulate_race(model, track_id=None, total_laps=12, num_drivers=8, drivers=None, teams=None, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    model.eval()\n",
    "    track_id = track_id or next(iter(track_scalers.keys()))\n",
    "    track_stats = track_scalers[track_id]\n",
    "    track_token = vocab.track_to_idx.get(track_id, 0)\n",
    "    slots = CONFIG.max_drivers\n",
    "    num_drivers = min(num_drivers, slots)\n",
    "\n",
    "    if drivers is None:\n",
    "        top_drivers = (\n",
    "            raw_df[raw_df['year'].isin(CONFIG.train_years)]\n",
    "            .groupby('driver_id')\n",
    "            .size()\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "        drivers = top_drivers.head(num_drivers).index.tolist()\n",
    "    else:\n",
    "        drivers = drivers[:num_drivers]\n",
    "\n",
    "    if teams is None:\n",
    "        first_team = (\n",
    "            raw_df.dropna(subset=['team_id'])\n",
    "            .drop_duplicates('driver_id')\n",
    "            .set_index('driver_id')['team_id']\n",
    "        )\n",
    "        teams = [first_team.get(drv, \"TEAM_SIM\") for drv in drivers]\n",
    "    else:\n",
    "        teams = teams[:num_drivers]\n",
    "\n",
    "    dyn_dim = session_tensors[0].dynamic_numeric.shape[-1]\n",
    "    global_dim = session_tensors[0].global_numeric.shape[-1]\n",
    "    static_dim = session_tensors[0].static_numeric.shape[-1]\n",
    "\n",
    "    dynamic = np.zeros((total_laps, slots, dyn_dim), dtype=np.float32)\n",
    "    rank_tokens = np.zeros((total_laps, slots), dtype=np.int64)\n",
    "    compound_tokens = np.zeros((total_laps, slots), dtype=np.int64)\n",
    "    alive = np.zeros((total_laps, slots), dtype=np.float32)\n",
    "    global_feats = np.zeros((total_laps, global_dim), dtype=np.float32)\n",
    "    driver_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "    team_tokens = np.zeros((slots,), dtype=np.int64)\n",
    "    static_numeric = np.zeros((slots, static_dim), dtype=np.float32)\n",
    "    laps_on_tyre = np.ones((slots,), dtype=np.float32)\n",
    "    gap_to_leader = np.zeros((slots,), dtype=np.float32)\n",
    "\n",
    "    compound_idx = vocab.compound_to_idx.get('UNKNOWN', 0)\n",
    "    compound_tokens[:, :num_drivers] = compound_idx\n",
    "    alive[:, :num_drivers] = 1.0\n",
    "\n",
    "    for slot in range(num_drivers):\n",
    "        driver_tokens[slot] = vocab.driver_to_idx.get(drivers[slot], 0)\n",
    "        team_tokens[slot] = vocab.team_to_idx.get(teams[slot], 0)\n",
    "        static_numeric[slot, 0] = float(slot + 1) / CONFIG.max_drivers\n",
    "        static_numeric[slot, 1] = (CONFIG.train_years[-1] - 2018) / 10.0\n",
    "\n",
    "    for lap_idx in range(total_laps):\n",
    "        lap_no = lap_idx + 1\n",
    "        frac = lap_no / total_laps\n",
    "        remaining = (total_laps - lap_no) / total_laps\n",
    "        global_feats[lap_idx, 0] = frac\n",
    "        global_feats[lap_idx, 1] = remaining\n",
    "        for g_idx, col in enumerate(['track_temperature', 'air_temperature', 'humidity', 'wind_speed'], start=2):\n",
    "            noise = rng.normal(0.0, 0.35)\n",
    "            global_feats[lap_idx, g_idx] = noise\n",
    "        global_feats[lap_idx, 6] = 0.0  # no rain\n",
    "        global_feats[lap_idx, 7] = 0.0  # neutral pressure\n",
    "\n",
    "    lap_mean, lap_std = track_stats['lap_time_s']\n",
    "    gap_mean, gap_std = track_stats['gap_to_leader_s']\n",
    "    ahead_mean, ahead_std = track_stats['gap_to_ahead_s']\n",
    "\n",
    "    def gap_z(val, mean, std):\n",
    "        return float((val - mean) / (std if std > 1e-6 else 1.0))\n",
    "\n",
    "    # Seed lap 1 with grid order, mean lap time, and small base gaps.\n",
    "    for slot in range(num_drivers):\n",
    "        grid_norm = float(slot + 1) / CONFIG.max_drivers\n",
    "        pos_norm = float(slot) / max(1, CONFIG.max_drivers - 1)\n",
    "        dynamic[0, slot, 0] = pos_norm\n",
    "        dynamic[0, slot, 1] = grid_norm\n",
    "        dynamic[0, slot, 2] = 0.0\n",
    "        dynamic[0, slot, 3] = 0.0\n",
    "        dynamic[0, slot, 4] = 0.0\n",
    "        base_gap = rng.uniform(0.3, 1.2) * slot\n",
    "        gap_to_leader[slot] = base_gap\n",
    "        gap_ahead = base_gap - (gap_to_leader[slot - 1] if slot > 0 else 0.0)\n",
    "        dynamic[0, slot, 5] = gap_z(np.log1p(gap_to_leader[slot]), np.log1p(gap_mean), gap_std)\n",
    "        dynamic[0, slot, 6] = gap_z(np.log1p(max(gap_ahead, 1e-3)), np.log1p(ahead_mean), ahead_std)\n",
    "        dynamic[0, slot, 7] = laps_on_tyre[slot] / 50.0\n",
    "        dynamic[0, slot, 8] = 0.0\n",
    "        dynamic[0, slot, 9] = 0.0\n",
    "        dynamic[0, slot, 10] = 0.0\n",
    "        dynamic[0, slot, 11] = 0.0\n",
    "        rank_tokens[0, slot] = slot\n",
    "\n",
    "    records = []\n",
    "    for slot in range(num_drivers):\n",
    "        records.append({\n",
    "            'lap': 1,\n",
    "            'driver_id': drivers[slot],\n",
    "            'driver_slot': slot + 1,\n",
    "            'pred_position': slot + 1,\n",
    "            'pred_lap_time_s': lap_mean,\n",
    "        })\n",
    "\n",
    "    debug_log = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lap_idx in range(1, total_laps):\n",
    "            context_len = lap_idx\n",
    "            batch = {\n",
    "                'dynamic': torch.from_numpy(dynamic[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'global': torch.from_numpy(global_feats[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'compound_tokens': torch.from_numpy(compound_tokens[:context_len]).unsqueeze(0).long().to(DEVICE),\n",
    "                'rank_tokens': torch.from_numpy(rank_tokens[:context_len]).unsqueeze(0).long().to(DEVICE),\n",
    "                'alive_mask': torch.from_numpy(alive[:context_len]).unsqueeze(0).float().to(DEVICE),\n",
    "                'context_length': torch.tensor([context_len], device=DEVICE),\n",
    "                'driver_tokens': torch.from_numpy(driver_tokens).unsqueeze(0).long().to(DEVICE),\n",
    "                'team_tokens': torch.from_numpy(team_tokens).unsqueeze(0).long().to(DEVICE),\n",
    "                'static_numeric': torch.from_numpy(static_numeric).unsqueeze(0).float().to(DEVICE),\n",
    "                'track_token': torch.tensor([track_token], device=DEVICE).long(),\n",
    "            }\n",
    "\n",
    "            preds = model(batch)\n",
    "            lap_time_norm = preds['lap_time'][0, :num_drivers].cpu().numpy()\n",
    "            pos_norm = preds['position'][0, :num_drivers].cpu().numpy()\n",
    "            pos_norm = np.clip(pos_norm, 0.0, 1.0)\n",
    "\n",
    "            debug_log.append({\n",
    "                'lap': lap_idx + 1,\n",
    "                'min_z': float(lap_time_norm.min()),\n",
    "                'max_z': float(lap_time_norm.max()),\n",
    "                'mean_z': float(lap_time_norm.mean()),\n",
    "            })\n",
    "\n",
    "            ranks = np.argsort(pos_norm)\n",
    "            slot_rank = np.zeros(num_drivers, dtype=np.int64)\n",
    "            slot_rank[ranks] = np.arange(num_drivers)\n",
    "            rank_tokens[lap_idx, :num_drivers] = slot_rank\n",
    "\n",
    "            drift = rng.normal(0.0, 0.3, size=num_drivers) + slot_rank * 0.2\n",
    "            gap_to_leader[:num_drivers] += drift.astype(np.float32)\n",
    "            gap_to_leader[:num_drivers] = np.maximum(gap_to_leader[:num_drivers], 0.0)\n",
    "            gap_to_leader[:num_drivers] -= gap_to_leader[:num_drivers].min()\n",
    "            gap_ahead = np.diff(np.concatenate([[0.0], gap_to_leader[:num_drivers]]))\n",
    "\n",
    "            for slot in range(num_drivers):\n",
    "                laps_on_tyre[slot] = min(laps_on_tyre[slot] + 1, 50)\n",
    "                if lap_idx > 0 and (lap_idx % 8 == 0) and slot == rng.integers(0, num_drivers):\n",
    "                    laps_on_tyre[slot] = 1\n",
    "                    dynamic[lap_idx, slot, 8] = 1.0\n",
    "                dynamic[lap_idx, slot, 0] = pos_norm[slot]\n",
    "                dynamic[lap_idx, slot, 1] = float(slot + 1) / CONFIG.max_drivers\n",
    "                dynamic[lap_idx, slot, 2] = lap_time_norm[slot]\n",
    "                dynamic[lap_idx, slot, 3] = dynamic[lap_idx - 1, slot, 2]\n",
    "                dynamic[lap_idx, slot, 4] = dynamic[lap_idx - 2, slot, 2] if lap_idx >= 2 else dynamic[lap_idx - 1, slot, 2]\n",
    "                dynamic[lap_idx, slot, 5] = gap_z(np.log1p(gap_to_leader[slot]), np.log1p(gap_mean), gap_std)\n",
    "                gap_ahead_val = max(gap_ahead[slot], 1e-3) if slot < len(gap_ahead) else gap_ahead[-1]\n",
    "                dynamic[lap_idx, slot, 6] = gap_z(np.log1p(gap_ahead_val), np.log1p(ahead_mean), ahead_std)\n",
    "                dynamic[lap_idx, slot, 7] = laps_on_tyre[slot] / 50.0\n",
    "                dynamic[lap_idx, slot, 8] = dynamic[lap_idx, slot, 8] if dynamic[lap_idx, slot, 8] else 0.0\n",
    "                dynamic[lap_idx, slot, 9] = 0.0\n",
    "                dynamic[lap_idx, slot, 10] = 0.0\n",
    "                dynamic[lap_idx, slot, 11] = 0.0\n",
    "\n",
    "            lap_times_s = lap_time_norm * lap_std + lap_mean\n",
    "            for slot in range(num_drivers):\n",
    "                records.append({\n",
    "                    'lap': lap_idx + 1,\n",
    "                    'driver_id': drivers[slot],\n",
    "                    'driver_slot': slot + 1,\n",
    "                    'pred_position': int(slot_rank[slot] + 1),\n",
    "                    'pred_lap_time_s': float(lap_times_s[slot]),\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    lap_time_table = df.pivot(index='lap', columns='driver_id', values='pred_lap_time_s')\n",
    "    position_table = df.pivot(index='lap', columns='driver_id', values='pred_position')\n",
    "    debug_df = pd.DataFrame(debug_log)\n",
    "    return df, lap_time_table, position_table, debug_df\n",
    "\n",
    "sim_df, lap_time_table, position_table, debug_df = simulate_race(\n",
    "    model,\n",
    "    track_id=list(track_scalers.keys())[0],\n",
    "    total_laps=12,\n",
    "    num_drivers=8,\n",
    ")\n",
    "print(sim_df.head(20))\n",
    "print(\"Lap times (s):\")\n",
    "print(lap_time_table.round(3))\n",
    "print(\"Positions (1=leader):\")\n",
    "print(position_table.astype(int))\n",
    "print(\"Predicted lap-time z-score stats per lap:\")\n",
    "print(debug_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}